{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import and Define\n",
        "Project 2: Time Series Forecasting using NN, LSTM, and CNN\n",
        "\n",
        "Authors: Jason Phillips and Peeja"
      ],
      "metadata": {
        "id": "ZCP-FQYIVHGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wUJ-a7xHp2M0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-explain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQeN9_0YV0fX",
        "outputId": "4535f00b-ac26-435a-9924-5cf4b03550dc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-explain in /usr/local/lib/python3.8/dist-packages (0.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I01Ot8YxSFtg",
        "outputId": "42ff1a56-27b8-4c95-daa9-7e8ac3fcb76e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Python 3.8.10 (default, Nov 14 2022, 12:59:47) \n",
            "[GCC 9.4.0]\n",
            "Pandas 1.3.5\n",
            "Numpy 1.22.4\n",
            "Scikit-Learn 1.2.1\n",
            "\n",
            "Tensor Flow 2.11.0\n",
            "Keras 2.11.0\n",
            "Imblearn 0.8.1\n"
          ]
        }
      ],
      "source": [
        "#Import and print out the current version of packages.\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tensorflow as tf\n",
        "import tf_explain\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import imblearn\n",
        "import io\n",
        "import requests\n",
        "import datetime\n",
        "\n",
        "from scipy.stats import zscore\n",
        "from collections.abc import Sequence\n",
        "from collections import Counter\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,LSTM\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import optimizers\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column. \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) * (normalized_high - normalized_low) + normalized_low\n",
        "\n",
        "# Plot a confusion matrix.\n",
        "# cm is the confusion matrix, names are the names of the classes.\n",
        "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(names))\n",
        "    plt.xticks(tick_marks, names, rotation=45)\n",
        "    plt.yticks(tick_marks, names)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    \n",
        "\n",
        "# Plot an ROC. pred - the predictions, y - the expected output.\n",
        "def plot_roc(pred,y):\n",
        "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "def to_sequences(seq_size, data):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-SEQUENCE_SIZE-1):\n",
        "        #print(i)\n",
        "        window = data[i:(i+SEQUENCE_SIZE)]\n",
        "        after_window = data[i+SEQUENCE_SIZE]\n",
        "        window = [[x] for x in window]\n",
        "        #print(\"{} - {}\".format(window,after_window))\n",
        "        x.append(window)\n",
        "        y.append(after_window)\n",
        "        \n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "print('Python {}'.format(sys.version))\n",
        "print('Pandas {}'.format(pd.__version__))\n",
        "print('Numpy {}'.format(np.__version__))\n",
        "print('Scikit-Learn {}'.format(sk.__version__))\n",
        "print()\n",
        "print('Tensor Flow {}'.format(tf.__version__))\n",
        "print('Keras {}'.format(tf.keras.__version__))\n",
        "print('Imblearn {}'.format(imblearn.__version__))\n",
        "\n",
        "#Remove any files in the log folder for tensorboard\n",
        "!rm -rf \"/content/drive/MyDrive/Colab Notebooks/logs/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the log folder for tensorboard\n",
        "log_dir = \"/content/drive/MyDrive/Colab Notebooks/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ],
      "metadata": {
        "id": "ylpTgZxdkg-f"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing\n",
        "Import dataset and preprocess it."
      ],
      "metadata": {
        "id": "aRyH3mDJWMvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the dataframe and convert empty values to NA\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/JasonTPhillipsJr/CSC215/main/TSLA.csv', na_values=['NA', '?'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ak-C-uiVWZnI",
        "outputId": "fe040aaf-18d3-4418-ba34-d77c72bf0da2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "0     2010-06-29    1.266667    1.666667    1.169333    1.592667    1.592667   \n",
              "1     2010-06-30    1.719333    2.028000    1.553333    1.588667    1.588667   \n",
              "2     2010-07-01    1.666667    1.728000    1.351333    1.464000    1.464000   \n",
              "3     2010-07-02    1.533333    1.540000    1.247333    1.280000    1.280000   \n",
              "4     2010-07-06    1.333333    1.333333    1.055333    1.074000    1.074000   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "3186  2023-02-24  196.330002  197.669998  192.800003  196.880005  196.880005   \n",
              "3187  2023-02-27  202.029999  209.419998  201.259995  207.630005  207.630005   \n",
              "3188  2023-02-28  210.589996  211.229996  203.750000  205.710007  205.710007   \n",
              "3189  2023-03-01  206.210007  207.199997  198.520004  202.770004  202.770004   \n",
              "3190  2023-03-02  186.740005  193.750000  186.009995  190.899994  190.899994   \n",
              "\n",
              "         Volume  \n",
              "0     281494500  \n",
              "1     257806500  \n",
              "2     123282000  \n",
              "3      77097000  \n",
              "4     103003500  \n",
              "...         ...  \n",
              "3186  142228100  \n",
              "3187  161028300  \n",
              "3188  153144900  \n",
              "3189  156852800  \n",
              "3190  181979200  \n",
              "\n",
              "[3191 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bda2d34-951e-4090-8885-15e2541a2055\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-06-29</td>\n",
              "      <td>1.266667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.169333</td>\n",
              "      <td>1.592667</td>\n",
              "      <td>1.592667</td>\n",
              "      <td>281494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-06-30</td>\n",
              "      <td>1.719333</td>\n",
              "      <td>2.028000</td>\n",
              "      <td>1.553333</td>\n",
              "      <td>1.588667</td>\n",
              "      <td>1.588667</td>\n",
              "      <td>257806500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-07-01</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.728000</td>\n",
              "      <td>1.351333</td>\n",
              "      <td>1.464000</td>\n",
              "      <td>1.464000</td>\n",
              "      <td>123282000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-07-02</td>\n",
              "      <td>1.533333</td>\n",
              "      <td>1.540000</td>\n",
              "      <td>1.247333</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>77097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-07-06</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.055333</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>103003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3186</th>\n",
              "      <td>2023-02-24</td>\n",
              "      <td>196.330002</td>\n",
              "      <td>197.669998</td>\n",
              "      <td>192.800003</td>\n",
              "      <td>196.880005</td>\n",
              "      <td>196.880005</td>\n",
              "      <td>142228100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3187</th>\n",
              "      <td>2023-02-27</td>\n",
              "      <td>202.029999</td>\n",
              "      <td>209.419998</td>\n",
              "      <td>201.259995</td>\n",
              "      <td>207.630005</td>\n",
              "      <td>207.630005</td>\n",
              "      <td>161028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3188</th>\n",
              "      <td>2023-02-28</td>\n",
              "      <td>210.589996</td>\n",
              "      <td>211.229996</td>\n",
              "      <td>203.750000</td>\n",
              "      <td>205.710007</td>\n",
              "      <td>205.710007</td>\n",
              "      <td>153144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3189</th>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>206.210007</td>\n",
              "      <td>207.199997</td>\n",
              "      <td>198.520004</td>\n",
              "      <td>202.770004</td>\n",
              "      <td>202.770004</td>\n",
              "      <td>156852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3190</th>\n",
              "      <td>2023-03-02</td>\n",
              "      <td>186.740005</td>\n",
              "      <td>193.750000</td>\n",
              "      <td>186.009995</td>\n",
              "      <td>190.899994</td>\n",
              "      <td>190.899994</td>\n",
              "      <td>181979200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3191 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bda2d34-951e-4090-8885-15e2541a2055')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bda2d34-951e-4090-8885-15e2541a2055 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bda2d34-951e-4090-8885-15e2541a2055');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if any values are empty or null\n",
        "df[df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w8j1_ee3_tFm",
        "outputId": "5fe8dcb3-bcf0-46c4-81a2-6305f9c31722"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05257f27-3227-4dbc-9f68-eb289468c509\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05257f27-3227-4dbc-9f68-eb289468c509')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05257f27-3227-4dbc-9f68-eb289468c509 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05257f27-3227-4dbc-9f68-eb289468c509');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display data types for each column\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb3R_PIBX1qC",
        "outputId": "8227c1a7-e424-4684-94b0-4f26ae4ca2c8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date          object\n",
              "Open         float64\n",
              "High         float64\n",
              "Low          float64\n",
              "Close        float64\n",
              "Adj Close    float64\n",
              "Volume         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some statistics for each column.\n",
        "data = {'Mean': df.mean(),\n",
        "        'Max': df.max(),\n",
        "        'Min': df.min(),\n",
        "        'Variaence': df.var(),\n",
        "        'STD': df.std()}\n",
        "\n",
        "dataframe = pd.DataFrame(data)\n",
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TnBUulL2X5a2",
        "outputId": "980a8b16-ed87-4e90-8b77-c67595544b46"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-0e371d19d6b4>:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  data = {'Mean': df.mean(),\n",
            "<ipython-input-43-0e371d19d6b4>:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  'Variaence': df.var(),\n",
            "<ipython-input-43-0e371d19d6b4>:6: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  'STD': df.std()}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Mean         Max         Min     Variaence           STD\n",
              "Adj Close  6.020587e+01  409.970001    1.053333  9.175041e+03  9.578644e+01\n",
              "Close      6.020587e+01  409.970001    1.053333  9.175041e+03  9.578644e+01\n",
              "Date                NaN  2023-03-02  2010-06-29           NaN           NaN\n",
              "High       6.160542e+01  414.496674    1.108667  9.626803e+03  9.811627e+01\n",
              "Low        5.874202e+01  405.666656    0.998667  8.724170e+03  9.340326e+01\n",
              "Open       6.023675e+01  411.470001       1.076  9.195453e+03  9.589293e+01\n",
              "Volume     9.485638e+07   914082000     1777500  6.723681e+15  8.199805e+07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d7723eb-f31b-4725-83c5-169cb031c25b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Max</th>\n",
              "      <th>Min</th>\n",
              "      <th>Variaence</th>\n",
              "      <th>STD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adj Close</th>\n",
              "      <td>6.020587e+01</td>\n",
              "      <td>409.970001</td>\n",
              "      <td>1.053333</td>\n",
              "      <td>9.175041e+03</td>\n",
              "      <td>9.578644e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Close</th>\n",
              "      <td>6.020587e+01</td>\n",
              "      <td>409.970001</td>\n",
              "      <td>1.053333</td>\n",
              "      <td>9.175041e+03</td>\n",
              "      <td>9.578644e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-03-02</td>\n",
              "      <td>2010-06-29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High</th>\n",
              "      <td>6.160542e+01</td>\n",
              "      <td>414.496674</td>\n",
              "      <td>1.108667</td>\n",
              "      <td>9.626803e+03</td>\n",
              "      <td>9.811627e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Low</th>\n",
              "      <td>5.874202e+01</td>\n",
              "      <td>405.666656</td>\n",
              "      <td>0.998667</td>\n",
              "      <td>8.724170e+03</td>\n",
              "      <td>9.340326e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Open</th>\n",
              "      <td>6.023675e+01</td>\n",
              "      <td>411.470001</td>\n",
              "      <td>1.076</td>\n",
              "      <td>9.195453e+03</td>\n",
              "      <td>9.589293e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <td>9.485638e+07</td>\n",
              "      <td>914082000</td>\n",
              "      <td>1777500</td>\n",
              "      <td>6.723681e+15</td>\n",
              "      <td>8.199805e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d7723eb-f31b-4725-83c5-169cb031c25b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d7723eb-f31b-4725-83c5-169cb031c25b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d7723eb-f31b-4725-83c5-169cb031c25b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop columns that aren't needed\n",
        "df = df.drop(['Date', 'Adj Close'], axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q3N1oD78aHKL",
        "outputId": "ad5cbbe9-5521-4c82-ee58-8bac50725d20"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Open        High         Low       Close     Volume\n",
              "0       1.266667    1.666667    1.169333    1.592667  281494500\n",
              "1       1.719333    2.028000    1.553333    1.588667  257806500\n",
              "2       1.666667    1.728000    1.351333    1.464000  123282000\n",
              "3       1.533333    1.540000    1.247333    1.280000   77097000\n",
              "4       1.333333    1.333333    1.055333    1.074000  103003500\n",
              "...          ...         ...         ...         ...        ...\n",
              "3186  196.330002  197.669998  192.800003  196.880005  142228100\n",
              "3187  202.029999  209.419998  201.259995  207.630005  161028300\n",
              "3188  210.589996  211.229996  203.750000  205.710007  153144900\n",
              "3189  206.210007  207.199997  198.520004  202.770004  156852800\n",
              "3190  186.740005  193.750000  186.009995  190.899994  181979200\n",
              "\n",
              "[3191 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72ee9a72-55ae-4b68-80a9-81abe5e0cc7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.266667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.169333</td>\n",
              "      <td>1.592667</td>\n",
              "      <td>281494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.719333</td>\n",
              "      <td>2.028000</td>\n",
              "      <td>1.553333</td>\n",
              "      <td>1.588667</td>\n",
              "      <td>257806500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.728000</td>\n",
              "      <td>1.351333</td>\n",
              "      <td>1.464000</td>\n",
              "      <td>123282000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.533333</td>\n",
              "      <td>1.540000</td>\n",
              "      <td>1.247333</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>77097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.055333</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>103003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3186</th>\n",
              "      <td>196.330002</td>\n",
              "      <td>197.669998</td>\n",
              "      <td>192.800003</td>\n",
              "      <td>196.880005</td>\n",
              "      <td>142228100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3187</th>\n",
              "      <td>202.029999</td>\n",
              "      <td>209.419998</td>\n",
              "      <td>201.259995</td>\n",
              "      <td>207.630005</td>\n",
              "      <td>161028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3188</th>\n",
              "      <td>210.589996</td>\n",
              "      <td>211.229996</td>\n",
              "      <td>203.750000</td>\n",
              "      <td>205.710007</td>\n",
              "      <td>153144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3189</th>\n",
              "      <td>206.210007</td>\n",
              "      <td>207.199997</td>\n",
              "      <td>198.520004</td>\n",
              "      <td>202.770004</td>\n",
              "      <td>156852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3190</th>\n",
              "      <td>186.740005</td>\n",
              "      <td>193.750000</td>\n",
              "      <td>186.009995</td>\n",
              "      <td>190.899994</td>\n",
              "      <td>181979200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3191 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72ee9a72-55ae-4b68-80a9-81abe5e0cc7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72ee9a72-55ae-4b68-80a9-81abe5e0cc7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72ee9a72-55ae-4b68-80a9-81abe5e0cc7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a copy of the Close column to use for the output feature.\n",
        "df['Close_Output'] = df['Close']\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9AC3viTScsyl",
        "outputId": "52f21dcb-19e9-4ed1-ee5d-44ccf244ea0a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Open        High         Low       Close     Volume  Close_Output\n",
              "0       1.266667    1.666667    1.169333    1.592667  281494500      1.592667\n",
              "1       1.719333    2.028000    1.553333    1.588667  257806500      1.588667\n",
              "2       1.666667    1.728000    1.351333    1.464000  123282000      1.464000\n",
              "3       1.533333    1.540000    1.247333    1.280000   77097000      1.280000\n",
              "4       1.333333    1.333333    1.055333    1.074000  103003500      1.074000\n",
              "...          ...         ...         ...         ...        ...           ...\n",
              "3186  196.330002  197.669998  192.800003  196.880005  142228100    196.880005\n",
              "3187  202.029999  209.419998  201.259995  207.630005  161028300    207.630005\n",
              "3188  210.589996  211.229996  203.750000  205.710007  153144900    205.710007\n",
              "3189  206.210007  207.199997  198.520004  202.770004  156852800    202.770004\n",
              "3190  186.740005  193.750000  186.009995  190.899994  181979200    190.899994\n",
              "\n",
              "[3191 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2100c597-a1f7-4847-8e17-26c979389bc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.266667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.169333</td>\n",
              "      <td>1.592667</td>\n",
              "      <td>281494500</td>\n",
              "      <td>1.592667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.719333</td>\n",
              "      <td>2.028000</td>\n",
              "      <td>1.553333</td>\n",
              "      <td>1.588667</td>\n",
              "      <td>257806500</td>\n",
              "      <td>1.588667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.728000</td>\n",
              "      <td>1.351333</td>\n",
              "      <td>1.464000</td>\n",
              "      <td>123282000</td>\n",
              "      <td>1.464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.533333</td>\n",
              "      <td>1.540000</td>\n",
              "      <td>1.247333</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>77097000</td>\n",
              "      <td>1.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.055333</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>103003500</td>\n",
              "      <td>1.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3186</th>\n",
              "      <td>196.330002</td>\n",
              "      <td>197.669998</td>\n",
              "      <td>192.800003</td>\n",
              "      <td>196.880005</td>\n",
              "      <td>142228100</td>\n",
              "      <td>196.880005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3187</th>\n",
              "      <td>202.029999</td>\n",
              "      <td>209.419998</td>\n",
              "      <td>201.259995</td>\n",
              "      <td>207.630005</td>\n",
              "      <td>161028300</td>\n",
              "      <td>207.630005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3188</th>\n",
              "      <td>210.589996</td>\n",
              "      <td>211.229996</td>\n",
              "      <td>203.750000</td>\n",
              "      <td>205.710007</td>\n",
              "      <td>153144900</td>\n",
              "      <td>205.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3189</th>\n",
              "      <td>206.210007</td>\n",
              "      <td>207.199997</td>\n",
              "      <td>198.520004</td>\n",
              "      <td>202.770004</td>\n",
              "      <td>156852800</td>\n",
              "      <td>202.770004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3190</th>\n",
              "      <td>186.740005</td>\n",
              "      <td>193.750000</td>\n",
              "      <td>186.009995</td>\n",
              "      <td>190.899994</td>\n",
              "      <td>181979200</td>\n",
              "      <td>190.899994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3191 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2100c597-a1f7-4847-8e17-26c979389bc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2100c597-a1f7-4847-8e17-26c979389bc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2100c597-a1f7-4847-8e17-26c979389bc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the Numeric Data\n",
        "df['Open'] = zscore(df['Open'])\n",
        "df['High'] = zscore(df['High'])\n",
        "df['Low'] = zscore(df['Low'])\n",
        "df['Close'] = zscore(df['Close'])\n",
        "df['Volume'] = zscore(df['Volume'])\n",
        "\n",
        "#Never normalize the output feature when traaining any regression models, else RMSE will also be normalized\n",
        "#df['Close_Output'] = zscore(df['Close_Output'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gPtUpZDHdbE1",
        "outputId": "26578a07-5e63-4e58-fcd1-f49479644dfc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Open      High       Low     Close    Volume  Close_Output\n",
              "0    -0.615054 -0.610991 -0.616485 -0.612011  2.276485      1.592667\n",
              "1    -0.610333 -0.607308 -0.612373 -0.612053  1.987555      1.588667\n",
              "2    -0.610882 -0.610366 -0.614536 -0.613355  0.346716      1.464000\n",
              "3    -0.612273 -0.612282 -0.615650 -0.615276 -0.216617      1.280000\n",
              "4    -0.614359 -0.614389 -0.617706 -0.617427  0.099373      1.074000\n",
              "...        ...       ...       ...       ...       ...           ...\n",
              "3186  1.419443  1.386986  1.435485  1.427087  0.577808    196.880005\n",
              "3187  1.478894  1.506761  1.526074  1.539333  0.807120    207.630005\n",
              "3188  1.568174  1.525211  1.552737  1.519285  0.710964    205.710007\n",
              "3189  1.522491  1.484131  1.496735  1.488587  0.756190    202.770004\n",
              "3190  1.319420  1.347027  1.362778  1.364646  1.062665    190.899994\n",
              "\n",
              "[3191 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b510651-c861-4416-aba3-9b8d305d3620\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615054</td>\n",
              "      <td>-0.610991</td>\n",
              "      <td>-0.616485</td>\n",
              "      <td>-0.612011</td>\n",
              "      <td>2.276485</td>\n",
              "      <td>1.592667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.610333</td>\n",
              "      <td>-0.607308</td>\n",
              "      <td>-0.612373</td>\n",
              "      <td>-0.612053</td>\n",
              "      <td>1.987555</td>\n",
              "      <td>1.588667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.610882</td>\n",
              "      <td>-0.610366</td>\n",
              "      <td>-0.614536</td>\n",
              "      <td>-0.613355</td>\n",
              "      <td>0.346716</td>\n",
              "      <td>1.464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.612273</td>\n",
              "      <td>-0.612282</td>\n",
              "      <td>-0.615650</td>\n",
              "      <td>-0.615276</td>\n",
              "      <td>-0.216617</td>\n",
              "      <td>1.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.614359</td>\n",
              "      <td>-0.614389</td>\n",
              "      <td>-0.617706</td>\n",
              "      <td>-0.617427</td>\n",
              "      <td>0.099373</td>\n",
              "      <td>1.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3186</th>\n",
              "      <td>1.419443</td>\n",
              "      <td>1.386986</td>\n",
              "      <td>1.435485</td>\n",
              "      <td>1.427087</td>\n",
              "      <td>0.577808</td>\n",
              "      <td>196.880005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3187</th>\n",
              "      <td>1.478894</td>\n",
              "      <td>1.506761</td>\n",
              "      <td>1.526074</td>\n",
              "      <td>1.539333</td>\n",
              "      <td>0.807120</td>\n",
              "      <td>207.630005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3188</th>\n",
              "      <td>1.568174</td>\n",
              "      <td>1.525211</td>\n",
              "      <td>1.552737</td>\n",
              "      <td>1.519285</td>\n",
              "      <td>0.710964</td>\n",
              "      <td>205.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3189</th>\n",
              "      <td>1.522491</td>\n",
              "      <td>1.484131</td>\n",
              "      <td>1.496735</td>\n",
              "      <td>1.488587</td>\n",
              "      <td>0.756190</td>\n",
              "      <td>202.770004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3190</th>\n",
              "      <td>1.319420</td>\n",
              "      <td>1.347027</td>\n",
              "      <td>1.362778</td>\n",
              "      <td>1.364646</td>\n",
              "      <td>1.062665</td>\n",
              "      <td>190.899994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3191 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b510651-c861-4416-aba3-9b8d305d3620')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b510651-c861-4416-aba3-9b8d305d3620 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b510651-c861-4416-aba3-9b8d305d3620');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting the Data\n",
        "Create test and training splits with a 30/70 split\n",
        "\n",
        "Now we have two Dataframes: df and df_y for input/output.\n",
        "reshape df to be a sequence of 35 inputs per output."
      ],
      "metadata": {
        "id": "CsckhRnkjAHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.externals._packaging.version import Tuple\n",
        "#Setup our Input and ouput features to be of the correct shape.\n",
        "#We want the first seven rows and 5 columns per prediction. 35 values total\n",
        "#Since we have 3191 Rows of data. rows/7 = 455 rows as input vectors with 35 values in each vector.\n",
        "SEQUENCE_SIZE = 7\n",
        "def create_dataset(time_step, data):\n",
        "  x = []  #input\n",
        "  y = []  #output\n",
        "  for i in range(len(data)-time_step-1):\n",
        "    x_temp = data.loc[i:i+time_step-1,[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
        "    x.append(x_temp)\n",
        "    y_temp = data.loc[i+time_step,[\"Close_Output\"]]   #Note, we take the (i+1)th value instead of the ith because we are looking at the close for the next day after the time_step.\n",
        "    y.append(y_temp)\n",
        "  return x,y\n",
        "\n",
        "x,y = create_dataset(SEQUENCE_SIZE, df)"
      ],
      "metadata": {
        "id": "JNd6MoRo85sU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure x is of the correct shape\n",
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHdYvy6i9lR8",
        "outputId": "12bd66bd-be6e-40e6-b480-02a2172717c6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3183"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure we have the right size\n",
        "print(x[1])\n",
        "print(len(x[1]))\n",
        "print(len(y))\n",
        "print(y[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKYAw9gY-RMU",
        "outputId": "0afcd96e-4cc3-4299-b5f4-cc487fce4efd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Open      High       Low     Close    Volume\n",
            "1 -0.610333 -0.607308 -0.612373 -0.612053  1.987555\n",
            "2 -0.610882 -0.610366 -0.614536 -0.613355  0.346716\n",
            "3 -0.612273 -0.612282 -0.615650 -0.615276 -0.216617\n",
            "4 -0.614359 -0.614389 -0.617706 -0.617427  0.099373\n",
            "5 -0.616862 -0.616679 -0.618312 -0.617643  0.109399\n",
            "6 -0.617043 -0.616074 -0.617891 -0.616487  0.253883\n",
            "7 -0.616041 -0.615816 -0.617192 -0.616529 -0.415897\n",
            "7\n",
            "3183\n",
            "Close_Output    1.136667\n",
            "Name: 8, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert x and y to numpy arrays for tensorflow\n",
        "#Reshape the arrays to be of the correct size for problem 1.\n",
        "num_rows = len(x)\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "oTPBB2Ti-acW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_NN = x.reshape(num_rows,35)\n",
        "y_NN = y.reshape(num_rows,1)"
      ],
      "metadata": {
        "id": "_zB934Hnnj4_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Choose only the 8th input from the output column. After 7 days make a prediction.\n",
        "y = []\n",
        "i = 1\n",
        "counter = 0\n",
        "while i in range(len(df_y)):\n",
        "  #print (i)\n",
        "  \n",
        "  if(counter == 7):\n",
        "    #print(\"i is\" + str(i))\n",
        "    #print(\"df at i is\" + str(df_y[i]))\n",
        "    counter = 0\n",
        "    y.append(df_y[i])\n",
        "  \n",
        "  counter += 1\n",
        "  i+=1\n",
        "\n",
        "y = np.array(y)\n",
        "y = y.reshape(455,1)\n",
        "#print(df_y.shape)\n",
        "print(y.shape)\n",
        "print(y)\n",
        "\n",
        "\"\"\"   "
      ],
      "metadata": {
        "id": "i2EeZQHKs0re",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "09d6a20e-bcdc-40cf-d449-2c3eb3de76bc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Choose only the 8th input from the output column. After 7 days make a prediction.\\ny = []\\ni = 1\\ncounter = 0\\nwhile i in range(len(df_y)):\\n  #print (i)\\n  \\n  if(counter == 7):\\n    #print(\"i is\" + str(i))\\n    #print(\"df at i is\" + str(df_y[i]))\\n    counter = 0\\n    y.append(df_y[i])\\n  \\n  counter += 1\\n  i+=1\\n\\ny = np.array(y)\\ny = y.reshape(455,1)\\n#print(df_y.shape)\\nprint(y.shape)\\nprint(y)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "x = []\n",
        "i = 0\n",
        "df = df.to_numpy()\n",
        "counter = 0\n",
        "while i in range(len(df)):\n",
        "  #print (i)\n",
        " \n",
        "  if(counter == 7):\n",
        "    #print(\"i is\" + str(i))\n",
        "    #print(\"df at i is\" + str(df[i]))\n",
        "    counter = 0\n",
        "    window = df[i:(i+7)]\n",
        "    #window = [[x] for x in window]\n",
        "    #print(\"{} - {}\".format(window,after_window))\n",
        "    x.append(window)\n",
        "  \n",
        "  counter += 1\n",
        "  i+=1\n",
        "\n",
        "\n",
        "x = np.array(x)\n",
        "#print(df.shape)\n",
        "x = x.reshape(455,35)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Szk7wRRRwPvF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "18df9f0b-7dcd-43a7-b9fd-f5af1ff5df04"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx = []\\ni = 0\\ndf = df.to_numpy()\\ncounter = 0\\nwhile i in range(len(df)):\\n  #print (i)\\n \\n  if(counter == 7):\\n    #print(\"i is\" + str(i))\\n    #print(\"df at i is\" + str(df[i]))\\n    counter = 0\\n    window = df[i:(i+7)]\\n    #window = [[x] for x in window]\\n    #print(\"{} - {}\".format(window,after_window))\\n    x.append(window)\\n  \\n  counter += 1\\n  i+=1\\n\\n\\nx = np.array(x)\\n#print(df.shape)\\nx = x.reshape(455,35)\\nprint(x.shape)\\nprint(x)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Remove the last few rows so that we can have an equal amount of weeks: 7 * 455 = 3185. Add 1 for the last output column value\n",
        "total_rows = 3186\n",
        "df = df[0:total_rows]\n",
        "df_y = df_y[0:total_rows]\n",
        "\n",
        "print(df.shape)\n",
        "print(df_y.shape)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kI_g69Bgqt5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e5a51300-0cde-4d38-fddf-aa608ceb89d5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Remove the last few rows so that we can have an equal amount of weeks: 7 * 455 = 3185. Add 1 for the last output column value\\ntotal_rows = 3186\\ndf = df[0:total_rows]\\ndf_y = df_y[0:total_rows]\\n\\nprint(df.shape)\\nprint(df_y.shape)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the x(inputs) and y(outputs)\n",
        "\n",
        "#Close_Output = df[\"Close_Output\"]\n",
        "#x,y = to_xy(df,\"Close_Output\")\n",
        "\n",
        "#Split the train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_NN, y_NN, test_size=0.30, random_state=42)\n"
      ],
      "metadata": {
        "id": "mhwvzFKwjJ9g"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ratio = 0.70\n",
        " \n",
        "#total_rows = df.shape[0]\n",
        "#train_size = int(total_rows*ratio)\n",
        " \n",
        "# Split data into test and train\n",
        "#df_train = df[0:train_size]\n",
        "#df_test = df[train_size:]\n",
        "\n",
        "#spots_train = df_train[\"Close_Output\"].tolist()\n",
        "#spots_test = df_test[\"Close_Output\"].tolist()\n",
        "\n",
        "#print(\"Training set has {} records.\".format(len(df_train)))\n",
        "#print(\"Test set has {} records.\".format(len(df_test)))\n",
        "#print(\"Shape of df_train: {}\".format(df_train.shape))\n",
        "#print(\"Shape of df_test: {}\".format(df_test.shape))"
      ],
      "metadata": {
        "id": "qcphWnHHQ9qE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "df_train = df.to_numpy()\n",
        "df_test = df.to_numpy()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vzliL0EVVUZ0",
        "outputId": "69cedd8c-d7c4-4ec2-ac66-b4e50b48baff"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndf_train = df.to_numpy()\\ndf_test = df.to_numpy()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "df_train.flatten()\n",
        "df_test.flatten()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Xs_ADnA3buF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0b376d25-d3f2-4fca-a9c5-a96d873cdcdf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndf_train.flatten()\\ndf_test.flatten()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SEQUENCE_SIZE = 35\n",
        "x_train,y_train = to_sequences(SEQUENCE_SIZE,df_train)\n",
        "x_test,y_test = to_sequences(SEQUENCE_SIZE,df_test)\n",
        "\n",
        "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
        "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
        "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
        "print(\"Shape of y_test: {}\".format(y_test.shape))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "o-X3bIzGS9sf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2f59c79a-920f-448e-f501-ac1d0699bb95"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSEQUENCE_SIZE = 35\\nx_train,y_train = to_sequences(SEQUENCE_SIZE,df_train)\\nx_test,y_test = to_sequences(SEQUENCE_SIZE,df_test)\\n\\nprint(\"Shape of x_train: {}\".format(x_train.shape))\\nprint(\"Shape of x_test: {}\".format(x_test.shape))\\nprint(\"Shape of y_train: {}\".format(y_train.shape))\\nprint(\"Shape of y_test: {}\".format(y_test.shape))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the shape for each array\n",
        "print(\"x shape: \" + str(x.shape))\n",
        "print(\"y shape: \" + str(y.shape))\n",
        "print()\n",
        "print(\"x_train shape: \" + str(x_train.shape))\n",
        "print(\"x_test shape: \" + str(x_test.shape))\n",
        "print()\n",
        "print(\"y_train shape: \" + str(y_train.shape))\n",
        "print(\"y_test shape: \" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izCzCQbjnGWe",
        "outputId": "4d11dcb7-1b93-4441-8bf9-da2b275ef98e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: (3183, 7, 5)\n",
            "y shape: (3183, 1)\n",
            "\n",
            "x_train shape: (2228, 35)\n",
            "x_test shape: (955, 35)\n",
            "\n",
            "y_train shape: (2228, 1)\n",
            "y_test shape: (955, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fully Connected Neural Network Model\n",
        "Use sequential model to process input vectors of 35 features per each 1 output\n",
        "\n"
      ],
      "metadata": {
        "id": "_OE0b0UJt-Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=x_NN.shape[1], activation='relu'))      # try changing 100 to 10\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])  #maybe remove accuracy because it = 0...\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=500)\n",
        "\n",
        "model.load_weights('dnn/best_weights.hdf5') # load weights from best model\n",
        "\n",
        "# Predict and measure RMSE\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Score (RMSE): {}\".format(score))\n",
        "\n",
        "# Plot the chart\n",
        "chart_regression(pred.flatten(),y_test, sort=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J21Fj6GduHpG",
        "outputId": "8c1400d0-ce92-4f86-bfd6-286b24fa4d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "70/70 - 2s - loss: 11302.7979 - accuracy: 0.0000e+00 - val_loss: 10426.1094 - val_accuracy: 0.0000e+00 - 2s/epoch - 27ms/step\n",
            "Epoch 2/500\n",
            "70/70 - 0s - loss: 5508.1123 - accuracy: 0.0000e+00 - val_loss: 1666.5608 - val_accuracy: 0.0000e+00 - 441ms/epoch - 6ms/step\n",
            "Epoch 3/500\n",
            "70/70 - 0s - loss: 381.0534 - accuracy: 0.0000e+00 - val_loss: 193.8696 - val_accuracy: 0.0000e+00 - 435ms/epoch - 6ms/step\n",
            "Epoch 4/500\n",
            "70/70 - 0s - loss: 183.3692 - accuracy: 0.0000e+00 - val_loss: 187.5800 - val_accuracy: 0.0000e+00 - 458ms/epoch - 7ms/step\n",
            "Epoch 5/500\n",
            "70/70 - 0s - loss: 176.2110 - accuracy: 0.0000e+00 - val_loss: 181.3109 - val_accuracy: 0.0000e+00 - 335ms/epoch - 5ms/step\n",
            "Epoch 6/500\n",
            "70/70 - 0s - loss: 170.6623 - accuracy: 0.0000e+00 - val_loss: 174.8448 - val_accuracy: 0.0000e+00 - 291ms/epoch - 4ms/step\n",
            "Epoch 7/500\n",
            "70/70 - 0s - loss: 163.9666 - accuracy: 0.0000e+00 - val_loss: 169.3730 - val_accuracy: 0.0000e+00 - 305ms/epoch - 4ms/step\n",
            "Epoch 8/500\n",
            "70/70 - 0s - loss: 158.7124 - accuracy: 0.0000e+00 - val_loss: 163.3164 - val_accuracy: 0.0000e+00 - 305ms/epoch - 4ms/step\n",
            "Epoch 9/500\n",
            "70/70 - 0s - loss: 155.0858 - accuracy: 0.0000e+00 - val_loss: 159.5506 - val_accuracy: 0.0000e+00 - 391ms/epoch - 6ms/step\n",
            "Epoch 10/500\n",
            "70/70 - 0s - loss: 147.9387 - accuracy: 0.0000e+00 - val_loss: 154.8364 - val_accuracy: 0.0000e+00 - 319ms/epoch - 5ms/step\n",
            "Epoch 11/500\n",
            "70/70 - 0s - loss: 144.5562 - accuracy: 0.0000e+00 - val_loss: 150.0123 - val_accuracy: 0.0000e+00 - 298ms/epoch - 4ms/step\n",
            "Epoch 12/500\n",
            "70/70 - 0s - loss: 137.7122 - accuracy: 0.0000e+00 - val_loss: 146.7608 - val_accuracy: 0.0000e+00 - 304ms/epoch - 4ms/step\n",
            "Epoch 13/500\n",
            "70/70 - 0s - loss: 133.3608 - accuracy: 0.0000e+00 - val_loss: 137.3675 - val_accuracy: 0.0000e+00 - 296ms/epoch - 4ms/step\n",
            "Epoch 14/500\n",
            "70/70 - 0s - loss: 127.8400 - accuracy: 0.0000e+00 - val_loss: 132.3651 - val_accuracy: 0.0000e+00 - 297ms/epoch - 4ms/step\n",
            "Epoch 15/500\n",
            "70/70 - 0s - loss: 120.0008 - accuracy: 0.0000e+00 - val_loss: 125.1621 - val_accuracy: 0.0000e+00 - 322ms/epoch - 5ms/step\n",
            "Epoch 16/500\n",
            "70/70 - 0s - loss: 112.5524 - accuracy: 0.0000e+00 - val_loss: 118.5720 - val_accuracy: 0.0000e+00 - 393ms/epoch - 6ms/step\n",
            "Epoch 17/500\n",
            "70/70 - 0s - loss: 104.6547 - accuracy: 0.0000e+00 - val_loss: 110.2824 - val_accuracy: 0.0000e+00 - 306ms/epoch - 4ms/step\n",
            "Epoch 18/500\n",
            "70/70 - 0s - loss: 97.3463 - accuracy: 0.0000e+00 - val_loss: 101.3431 - val_accuracy: 0.0000e+00 - 316ms/epoch - 5ms/step\n",
            "Epoch 19/500\n",
            "70/70 - 0s - loss: 89.8318 - accuracy: 0.0000e+00 - val_loss: 96.6687 - val_accuracy: 0.0000e+00 - 310ms/epoch - 4ms/step\n",
            "Epoch 20/500\n",
            "70/70 - 0s - loss: 79.9728 - accuracy: 0.0000e+00 - val_loss: 85.4571 - val_accuracy: 0.0000e+00 - 291ms/epoch - 4ms/step\n",
            "Epoch 21/500\n",
            "70/70 - 0s - loss: 72.1449 - accuracy: 0.0000e+00 - val_loss: 77.1883 - val_accuracy: 0.0000e+00 - 320ms/epoch - 5ms/step\n",
            "Epoch 22/500\n",
            "70/70 - 0s - loss: 64.5504 - accuracy: 0.0000e+00 - val_loss: 69.9175 - val_accuracy: 0.0000e+00 - 310ms/epoch - 4ms/step\n",
            "Epoch 23/500\n",
            "70/70 - 0s - loss: 55.3402 - accuracy: 0.0000e+00 - val_loss: 65.9982 - val_accuracy: 0.0000e+00 - 290ms/epoch - 4ms/step\n",
            "Epoch 24/500\n",
            "70/70 - 0s - loss: 51.5523 - accuracy: 0.0000e+00 - val_loss: 58.4666 - val_accuracy: 0.0000e+00 - 298ms/epoch - 4ms/step\n",
            "Epoch 25/500\n",
            "70/70 - 0s - loss: 46.9886 - accuracy: 0.0000e+00 - val_loss: 54.0951 - val_accuracy: 0.0000e+00 - 304ms/epoch - 4ms/step\n",
            "Epoch 26/500\n",
            "70/70 - 0s - loss: 40.5020 - accuracy: 0.0000e+00 - val_loss: 50.5847 - val_accuracy: 0.0000e+00 - 303ms/epoch - 4ms/step\n",
            "Epoch 27/500\n",
            "70/70 - 0s - loss: 38.4242 - accuracy: 0.0000e+00 - val_loss: 51.1472 - val_accuracy: 0.0000e+00 - 279ms/epoch - 4ms/step\n",
            "Epoch 28/500\n",
            "70/70 - 0s - loss: 39.5381 - accuracy: 0.0000e+00 - val_loss: 47.8607 - val_accuracy: 0.0000e+00 - 296ms/epoch - 4ms/step\n",
            "Epoch 29/500\n",
            "70/70 - 0s - loss: 34.2502 - accuracy: 0.0000e+00 - val_loss: 45.0762 - val_accuracy: 0.0000e+00 - 299ms/epoch - 4ms/step\n",
            "Epoch 30/500\n",
            "70/70 - 0s - loss: 30.2212 - accuracy: 0.0000e+00 - val_loss: 56.4464 - val_accuracy: 0.0000e+00 - 269ms/epoch - 4ms/step\n",
            "Epoch 31/500\n",
            "70/70 - 0s - loss: 29.4462 - accuracy: 0.0000e+00 - val_loss: 43.9135 - val_accuracy: 0.0000e+00 - 306ms/epoch - 4ms/step\n",
            "Epoch 32/500\n",
            "70/70 - 0s - loss: 29.6948 - accuracy: 0.0000e+00 - val_loss: 37.3939 - val_accuracy: 0.0000e+00 - 312ms/epoch - 4ms/step\n",
            "Epoch 33/500\n",
            "70/70 - 0s - loss: 28.7944 - accuracy: 0.0000e+00 - val_loss: 37.2673 - val_accuracy: 0.0000e+00 - 295ms/epoch - 4ms/step\n",
            "Epoch 34/500\n",
            "70/70 - 0s - loss: 27.4199 - accuracy: 0.0000e+00 - val_loss: 38.1554 - val_accuracy: 0.0000e+00 - 296ms/epoch - 4ms/step\n",
            "Epoch 35/500\n",
            "70/70 - 0s - loss: 25.9053 - accuracy: 0.0000e+00 - val_loss: 40.9027 - val_accuracy: 0.0000e+00 - 292ms/epoch - 4ms/step\n",
            "Epoch 36/500\n",
            "70/70 - 0s - loss: 27.7612 - accuracy: 0.0000e+00 - val_loss: 40.0575 - val_accuracy: 0.0000e+00 - 291ms/epoch - 4ms/step\n",
            "Epoch 37/500\n",
            "70/70 - 0s - loss: 25.3497 - accuracy: 0.0000e+00 - val_loss: 35.5524 - val_accuracy: 0.0000e+00 - 438ms/epoch - 6ms/step\n",
            "Epoch 38/500\n",
            "70/70 - 0s - loss: 24.7880 - accuracy: 0.0000e+00 - val_loss: 36.7453 - val_accuracy: 0.0000e+00 - 405ms/epoch - 6ms/step\n",
            "Epoch 39/500\n",
            "70/70 - 0s - loss: 24.1009 - accuracy: 0.0000e+00 - val_loss: 40.6034 - val_accuracy: 0.0000e+00 - 469ms/epoch - 7ms/step\n",
            "Epoch 40/500\n",
            "70/70 - 0s - loss: 25.9609 - accuracy: 0.0000e+00 - val_loss: 37.6297 - val_accuracy: 0.0000e+00 - 443ms/epoch - 6ms/step\n",
            "Epoch 41/500\n",
            "70/70 - 0s - loss: 24.2009 - accuracy: 0.0000e+00 - val_loss: 35.7653 - val_accuracy: 0.0000e+00 - 470ms/epoch - 7ms/step\n",
            "Epoch 42/500\n",
            "70/70 - 0s - loss: 24.1470 - accuracy: 0.0000e+00 - val_loss: 39.1318 - val_accuracy: 0.0000e+00 - 296ms/epoch - 4ms/step\n",
            "Epoch 42: early stopping\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "Score (RMSE): 5.9625833839085445\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM Model\n",
        "Use Long Term Neural Network instead.\n",
        "\n",
        "Records should be viewed as a sequence of 7 vectors, each with 5 dimensions"
      ],
      "metadata": {
        "id": "0eyS0Bgii2K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GIfHR5es2K_W",
        "outputId": "a0fdedd1-4333-4630-ddbf-cf5ecc5b0199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Open      High       Low     Close    Volume  Close_Output\n",
              "0    -0.615054 -0.610991 -0.616485 -0.612011  2.276485      1.592667\n",
              "1    -0.610333 -0.607308 -0.612373 -0.612053  1.987555      1.588667\n",
              "2    -0.610882 -0.610366 -0.614536 -0.613355  0.346716      1.464000\n",
              "3    -0.612273 -0.612282 -0.615650 -0.615276 -0.216617      1.280000\n",
              "4    -0.614359 -0.614389 -0.617706 -0.617427  0.099373      1.074000\n",
              "...        ...       ...       ...       ...       ...           ...\n",
              "3186  1.419443  1.386986  1.435485  1.427087  0.577808    196.880005\n",
              "3187  1.478894  1.506761  1.526074  1.539333  0.807120    207.630005\n",
              "3188  1.568174  1.525211  1.552737  1.519285  0.710964    205.710007\n",
              "3189  1.522491  1.484131  1.496735  1.488587  0.756190    202.770004\n",
              "3190  1.319420  1.347027  1.362778  1.364646  1.062665    190.899994\n",
              "\n",
              "[3191 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-721dc702-0588-4c85-9efb-528ea217c093\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615054</td>\n",
              "      <td>-0.610991</td>\n",
              "      <td>-0.616485</td>\n",
              "      <td>-0.612011</td>\n",
              "      <td>2.276485</td>\n",
              "      <td>1.592667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.610333</td>\n",
              "      <td>-0.607308</td>\n",
              "      <td>-0.612373</td>\n",
              "      <td>-0.612053</td>\n",
              "      <td>1.987555</td>\n",
              "      <td>1.588667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.610882</td>\n",
              "      <td>-0.610366</td>\n",
              "      <td>-0.614536</td>\n",
              "      <td>-0.613355</td>\n",
              "      <td>0.346716</td>\n",
              "      <td>1.464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.612273</td>\n",
              "      <td>-0.612282</td>\n",
              "      <td>-0.615650</td>\n",
              "      <td>-0.615276</td>\n",
              "      <td>-0.216617</td>\n",
              "      <td>1.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.614359</td>\n",
              "      <td>-0.614389</td>\n",
              "      <td>-0.617706</td>\n",
              "      <td>-0.617427</td>\n",
              "      <td>0.099373</td>\n",
              "      <td>1.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3186</th>\n",
              "      <td>1.419443</td>\n",
              "      <td>1.386986</td>\n",
              "      <td>1.435485</td>\n",
              "      <td>1.427087</td>\n",
              "      <td>0.577808</td>\n",
              "      <td>196.880005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3187</th>\n",
              "      <td>1.478894</td>\n",
              "      <td>1.506761</td>\n",
              "      <td>1.526074</td>\n",
              "      <td>1.539333</td>\n",
              "      <td>0.807120</td>\n",
              "      <td>207.630005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3188</th>\n",
              "      <td>1.568174</td>\n",
              "      <td>1.525211</td>\n",
              "      <td>1.552737</td>\n",
              "      <td>1.519285</td>\n",
              "      <td>0.710964</td>\n",
              "      <td>205.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3189</th>\n",
              "      <td>1.522491</td>\n",
              "      <td>1.484131</td>\n",
              "      <td>1.496735</td>\n",
              "      <td>1.488587</td>\n",
              "      <td>0.756190</td>\n",
              "      <td>202.770004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3190</th>\n",
              "      <td>1.319420</td>\n",
              "      <td>1.347027</td>\n",
              "      <td>1.362778</td>\n",
              "      <td>1.364646</td>\n",
              "      <td>1.062665</td>\n",
              "      <td>190.899994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3191 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-721dc702-0588-4c85-9efb-528ea217c093')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-721dc702-0588-4c85-9efb-528ea217c093 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-721dc702-0588-4c85-9efb-528ea217c093');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1].shape)\n",
        "print(y[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A7RTbZgotUY",
        "outputId": "d7065d13-27ea-4264-e235-31453f0ebead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 5)\n",
            "(1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)"
      ],
      "metadata": {
        "id": "QfACV6lCjkTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5)))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])  #maybe remove accuracy because it = 0...\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
        "\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=500)\n",
        "\n",
        "model.load_weights('dnn/best_weights.hdf5') # load weights from best model\n",
        "\n",
        "# Predict and measure RMSE\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Score (RMSE): {}\".format(score))\n",
        "\n",
        "# Plot the chart\n",
        "chart_regression(pred.flatten(),y_test, sort=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "neUdS5eXlPnS",
        "outputId": "db99a94c-34b8-4091-eec4-aebdbc73dc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "70/70 - 6s - loss: 10512.0645 - accuracy: 0.0000e+00 - val_loss: 8754.9590 - val_accuracy: 0.0000e+00 - 6s/epoch - 92ms/step\n",
            "Epoch 2/500\n",
            "70/70 - 2s - loss: 5363.4849 - accuracy: 0.0000e+00 - val_loss: 3675.2307 - val_accuracy: 0.0000e+00 - 2s/epoch - 29ms/step\n",
            "Epoch 3/500\n",
            "70/70 - 4s - loss: 1981.8523 - accuracy: 0.0000e+00 - val_loss: 1208.1328 - val_accuracy: 0.0000e+00 - 4s/epoch - 64ms/step\n",
            "Epoch 4/500\n",
            "70/70 - 6s - loss: 713.6285 - accuracy: 0.0000e+00 - val_loss: 504.6869 - val_accuracy: 0.0000e+00 - 6s/epoch - 81ms/step\n",
            "Epoch 5/500\n",
            "70/70 - 4s - loss: 336.6852 - accuracy: 0.0000e+00 - val_loss: 259.7364 - val_accuracy: 0.0000e+00 - 4s/epoch - 56ms/step\n",
            "Epoch 6/500\n",
            "70/70 - 2s - loss: 215.2831 - accuracy: 0.0000e+00 - val_loss: 157.4941 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 7/500\n",
            "70/70 - 2s - loss: 156.7158 - accuracy: 0.0000e+00 - val_loss: 110.9448 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 8/500\n",
            "70/70 - 3s - loss: 119.9558 - accuracy: 0.0000e+00 - val_loss: 84.4755 - val_accuracy: 0.0000e+00 - 3s/epoch - 48ms/step\n",
            "Epoch 9/500\n",
            "70/70 - 2s - loss: 96.3929 - accuracy: 0.0000e+00 - val_loss: 71.4531 - val_accuracy: 0.0000e+00 - 2s/epoch - 29ms/step\n",
            "Epoch 10/500\n",
            "70/70 - 2s - loss: 100.9948 - accuracy: 0.0000e+00 - val_loss: 68.3392 - val_accuracy: 0.0000e+00 - 2s/epoch - 29ms/step\n",
            "Epoch 11/500\n",
            "70/70 - 2s - loss: 93.1247 - accuracy: 0.0000e+00 - val_loss: 61.1052 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 12/500\n",
            "70/70 - 2s - loss: 86.7688 - accuracy: 0.0000e+00 - val_loss: 60.7554 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 13/500\n",
            "70/70 - 3s - loss: 73.7453 - accuracy: 0.0000e+00 - val_loss: 61.1671 - val_accuracy: 0.0000e+00 - 3s/epoch - 42ms/step\n",
            "Epoch 14/500\n",
            "70/70 - 2s - loss: 75.7089 - accuracy: 0.0000e+00 - val_loss: 54.8267 - val_accuracy: 0.0000e+00 - 2s/epoch - 31ms/step\n",
            "Epoch 15/500\n",
            "70/70 - 2s - loss: 79.6831 - accuracy: 0.0000e+00 - val_loss: 54.6756 - val_accuracy: 0.0000e+00 - 2s/epoch - 29ms/step\n",
            "Epoch 16/500\n",
            "70/70 - 2s - loss: 68.0352 - accuracy: 0.0000e+00 - val_loss: 78.4520 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 17/500\n",
            "70/70 - 2s - loss: 73.7441 - accuracy: 0.0000e+00 - val_loss: 52.4071 - val_accuracy: 0.0000e+00 - 2s/epoch - 29ms/step\n",
            "Epoch 18/500\n",
            "70/70 - 2s - loss: 64.3755 - accuracy: 0.0000e+00 - val_loss: 53.2848 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 19/500\n",
            "70/70 - 3s - loss: 67.7049 - accuracy: 0.0000e+00 - val_loss: 44.5348 - val_accuracy: 0.0000e+00 - 3s/epoch - 45ms/step\n",
            "Epoch 20/500\n",
            "70/70 - 2s - loss: 58.6478 - accuracy: 0.0000e+00 - val_loss: 62.7142 - val_accuracy: 0.0000e+00 - 2s/epoch - 27ms/step\n",
            "Epoch 21/500\n",
            "70/70 - 2s - loss: 63.1150 - accuracy: 0.0000e+00 - val_loss: 51.5227 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 22/500\n",
            "70/70 - 2s - loss: 56.9042 - accuracy: 0.0000e+00 - val_loss: 46.9755 - val_accuracy: 0.0000e+00 - 2s/epoch - 28ms/step\n",
            "Epoch 23/500\n",
            "70/70 - 2s - loss: 55.3670 - accuracy: 0.0000e+00 - val_loss: 50.0970 - val_accuracy: 0.0000e+00 - 2s/epoch - 29ms/step\n",
            "Epoch 24/500\n",
            "70/70 - 3s - loss: 62.2247 - accuracy: 0.0000e+00 - val_loss: 65.6648 - val_accuracy: 0.0000e+00 - 3s/epoch - 38ms/step\n",
            "Epoch 24: early stopping\n",
            "30/30 [==============================] - 1s 6ms/step\n",
            "Score (RMSE): 6.673440385726653\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wvxsf0xlPvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Model\n",
        "Convolutional Neural Network\n",
        "\n",
        "Use Dense, convolution, max, dropout, and flatten layers to create the model.\n",
        "\n",
        "Output can be viewed as a 1D Image of 7 pixels, each pixel with 5 channels, or as a 2D image of 7*5 = 35 pixels, each pixel with 1 channel."
      ],
      "metadata": {
        "id": "XkXx3Iupv61d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize shapes before reshaping\n",
        "print(\"x shape: \" + str(x.shape))\n",
        "print(\"y shape: \" + str(y.shape))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
        "\n",
        "print(\"x_train shape: \" + str(x_train.shape))\n",
        "print(\"y_train shape: \" + str(y_train.shape))\n",
        "print(\"x_test shape: \" + str(x_test.shape))\n",
        "print(\"y_test shape: \" + str(y_test.shape))"
      ],
      "metadata": {
        "id": "craspOdOYj0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb6e514-409a-41f2-aadf-8abf998cc532"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: (3183, 7, 5)\n",
            "y shape: (3183, 1)\n",
            "x_train shape: (2228, 7, 5)\n",
            "y_train shape: (2228, 1)\n",
            "x_test shape: (955, 7, 5)\n",
            "y_test shape: (955, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape input to be a 4D Array of (number of samples, rows per sample, columns per sample, and number of channels)\n",
        "#Note since we aren't using an RGB image, our channels is 1.\n",
        "img_rows = 7\n",
        "img_cols = 5\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(\"x_train shape: \" + str(x_train.shape))\n",
        "print(\"x_test shape: \" + str(x_test.shape))"
      ],
      "metadata": {
        "id": "Gyw-U-WbYkaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45aa2084-97bc-41e8-dea2-e2f0f0cb841e"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (2228, 7, 5, 1)\n",
            "x_test shape: (955, 7, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(4, 4), strides=(1, 1), padding='same',  #include padding because we got some goofy dimensions\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))    #  in this case, input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "vC68Zp1TYkdM"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "R9w1U5d1Ykgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100477ba-ba71-4bd7-d226-9b884eb2c9f9"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (None, 7, 5, 256)         4352      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,352\n",
            "Trainable params: 4,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
        "model.add(Dropout(0.25)) "
      ],
      "metadata": {
        "id": "HgXQybzbYkjB"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "mTvldKDzf3S6"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3pphU7OgcAT",
        "outputId": "78327c0b-453c-4738-9ec8-328b2ad2ccf5"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (None, 7, 5, 256)         4352      \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 5, 3, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 2, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 2, 1, 64)          0         \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,513\n",
            "Trainable params: 168,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show not only log loss but also accuracy for each epoch using metrics=['accuracy']\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cOsDAlPygeg_"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "model.fit(x_train, y_train,     \n",
        "          batch_size=batch_size,\n",
        "          epochs=200,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "##model.load_weights('dnn/best_weights.hdf5') # load weights from best model\n",
        "\n",
        "# Predict and measure RMSE\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Score (RMSE): {}\".format(score))\n",
        "\n",
        "# Plot the chart\n",
        "chart_regression(pred.flatten(),y_test, sort=True)\n",
        "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A1mwKfvkg66i",
        "outputId": "e5487cf9-ce77-426c-d2af-d14ce927e021"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "9/9 - 2s - loss: 11877.1377 - accuracy: 0.0000e+00 - val_loss: 11471.7881 - val_accuracy: 0.0000e+00 - 2s/epoch - 200ms/step\n",
            "Epoch 2/200\n",
            "9/9 - 0s - loss: 7136.7866 - accuracy: 0.0000e+00 - val_loss: 1946.4259 - val_accuracy: 0.0000e+00 - 86ms/epoch - 10ms/step\n",
            "Epoch 3/200\n",
            "9/9 - 0s - loss: 1494.4904 - accuracy: 0.0000e+00 - val_loss: 897.8865 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 4/200\n",
            "9/9 - 0s - loss: 931.5327 - accuracy: 0.0000e+00 - val_loss: 1056.1384 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "9/9 - 0s - loss: 946.6779 - accuracy: 0.0000e+00 - val_loss: 232.8727 - val_accuracy: 0.0000e+00 - 82ms/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "9/9 - 0s - loss: 715.5552 - accuracy: 0.0000e+00 - val_loss: 231.7778 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 7/200\n",
            "9/9 - 0s - loss: 627.6308 - accuracy: 0.0000e+00 - val_loss: 299.5977 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 8/200\n",
            "9/9 - 0s - loss: 601.2039 - accuracy: 0.0000e+00 - val_loss: 223.9144 - val_accuracy: 0.0000e+00 - 146ms/epoch - 16ms/step\n",
            "Epoch 9/200\n",
            "9/9 - 0s - loss: 547.4366 - accuracy: 0.0000e+00 - val_loss: 248.2038 - val_accuracy: 0.0000e+00 - 115ms/epoch - 13ms/step\n",
            "Epoch 10/200\n",
            "9/9 - 0s - loss: 542.4097 - accuracy: 0.0000e+00 - val_loss: 218.6646 - val_accuracy: 0.0000e+00 - 126ms/epoch - 14ms/step\n",
            "Epoch 11/200\n",
            "9/9 - 0s - loss: 534.1147 - accuracy: 0.0000e+00 - val_loss: 204.6745 - val_accuracy: 0.0000e+00 - 111ms/epoch - 12ms/step\n",
            "Epoch 12/200\n",
            "9/9 - 0s - loss: 547.5649 - accuracy: 0.0000e+00 - val_loss: 204.1380 - val_accuracy: 0.0000e+00 - 147ms/epoch - 16ms/step\n",
            "Epoch 13/200\n",
            "9/9 - 0s - loss: 480.5274 - accuracy: 0.0000e+00 - val_loss: 180.5114 - val_accuracy: 0.0000e+00 - 108ms/epoch - 12ms/step\n",
            "Epoch 14/200\n",
            "9/9 - 0s - loss: 493.4773 - accuracy: 0.0000e+00 - val_loss: 207.0635 - val_accuracy: 0.0000e+00 - 105ms/epoch - 12ms/step\n",
            "Epoch 15/200\n",
            "9/9 - 0s - loss: 478.5616 - accuracy: 0.0000e+00 - val_loss: 165.6301 - val_accuracy: 0.0000e+00 - 122ms/epoch - 14ms/step\n",
            "Epoch 16/200\n",
            "9/9 - 0s - loss: 434.4071 - accuracy: 0.0000e+00 - val_loss: 146.8947 - val_accuracy: 0.0000e+00 - 115ms/epoch - 13ms/step\n",
            "Epoch 17/200\n",
            "9/9 - 0s - loss: 476.8184 - accuracy: 0.0000e+00 - val_loss: 202.2315 - val_accuracy: 0.0000e+00 - 126ms/epoch - 14ms/step\n",
            "Epoch 18/200\n",
            "9/9 - 0s - loss: 428.1100 - accuracy: 0.0000e+00 - val_loss: 127.3507 - val_accuracy: 0.0000e+00 - 110ms/epoch - 12ms/step\n",
            "Epoch 19/200\n",
            "9/9 - 0s - loss: 464.7237 - accuracy: 0.0000e+00 - val_loss: 132.3938 - val_accuracy: 0.0000e+00 - 158ms/epoch - 18ms/step\n",
            "Epoch 20/200\n",
            "9/9 - 0s - loss: 448.8716 - accuracy: 0.0000e+00 - val_loss: 130.6270 - val_accuracy: 0.0000e+00 - 115ms/epoch - 13ms/step\n",
            "Epoch 21/200\n",
            "9/9 - 0s - loss: 408.0300 - accuracy: 0.0000e+00 - val_loss: 108.3682 - val_accuracy: 0.0000e+00 - 114ms/epoch - 13ms/step\n",
            "Epoch 22/200\n",
            "9/9 - 0s - loss: 385.0900 - accuracy: 0.0000e+00 - val_loss: 113.0101 - val_accuracy: 0.0000e+00 - 112ms/epoch - 12ms/step\n",
            "Epoch 23/200\n",
            "9/9 - 0s - loss: 349.3518 - accuracy: 0.0000e+00 - val_loss: 88.8519 - val_accuracy: 0.0000e+00 - 133ms/epoch - 15ms/step\n",
            "Epoch 24/200\n",
            "9/9 - 0s - loss: 331.1310 - accuracy: 0.0000e+00 - val_loss: 115.2952 - val_accuracy: 0.0000e+00 - 118ms/epoch - 13ms/step\n",
            "Epoch 25/200\n",
            "9/9 - 0s - loss: 314.0439 - accuracy: 0.0000e+00 - val_loss: 76.0784 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 26/200\n",
            "9/9 - 0s - loss: 358.2851 - accuracy: 0.0000e+00 - val_loss: 72.1024 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 27/200\n",
            "9/9 - 0s - loss: 314.7989 - accuracy: 0.0000e+00 - val_loss: 70.2971 - val_accuracy: 0.0000e+00 - 85ms/epoch - 9ms/step\n",
            "Epoch 28/200\n",
            "9/9 - 0s - loss: 322.3340 - accuracy: 0.0000e+00 - val_loss: 102.8660 - val_accuracy: 0.0000e+00 - 86ms/epoch - 10ms/step\n",
            "Epoch 29/200\n",
            "9/9 - 0s - loss: 330.5359 - accuracy: 0.0000e+00 - val_loss: 101.4020 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 30/200\n",
            "9/9 - 0s - loss: 372.3934 - accuracy: 0.0000e+00 - val_loss: 77.4681 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 31/200\n",
            "9/9 - 0s - loss: 292.1240 - accuracy: 0.0000e+00 - val_loss: 73.8189 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 32/200\n",
            "9/9 - 0s - loss: 350.9034 - accuracy: 0.0000e+00 - val_loss: 79.5802 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 33/200\n",
            "9/9 - 0s - loss: 298.7876 - accuracy: 0.0000e+00 - val_loss: 67.0176 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 34/200\n",
            "9/9 - 0s - loss: 356.0121 - accuracy: 0.0000e+00 - val_loss: 66.1494 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 35/200\n",
            "9/9 - 0s - loss: 374.1971 - accuracy: 0.0000e+00 - val_loss: 65.9502 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 36/200\n",
            "9/9 - 0s - loss: 316.4125 - accuracy: 0.0000e+00 - val_loss: 78.5172 - val_accuracy: 0.0000e+00 - 85ms/epoch - 9ms/step\n",
            "Epoch 37/200\n",
            "9/9 - 0s - loss: 369.9333 - accuracy: 0.0000e+00 - val_loss: 63.5373 - val_accuracy: 0.0000e+00 - 84ms/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "9/9 - 0s - loss: 286.2221 - accuracy: 0.0000e+00 - val_loss: 62.4290 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 39/200\n",
            "9/9 - 0s - loss: 304.2918 - accuracy: 0.0000e+00 - val_loss: 62.4469 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 40/200\n",
            "9/9 - 0s - loss: 273.5609 - accuracy: 0.0000e+00 - val_loss: 138.9678 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 41/200\n",
            "9/9 - 0s - loss: 330.8394 - accuracy: 0.0000e+00 - val_loss: 128.1612 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 42/200\n",
            "9/9 - 0s - loss: 314.5885 - accuracy: 0.0000e+00 - val_loss: 156.9722 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 43/200\n",
            "9/9 - 0s - loss: 365.4842 - accuracy: 0.0000e+00 - val_loss: 80.8331 - val_accuracy: 0.0000e+00 - 102ms/epoch - 11ms/step\n",
            "Epoch 44/200\n",
            "9/9 - 0s - loss: 370.7659 - accuracy: 0.0000e+00 - val_loss: 73.2871 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 45/200\n",
            "9/9 - 0s - loss: 332.1718 - accuracy: 0.0000e+00 - val_loss: 70.8177 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 46/200\n",
            "9/9 - 0s - loss: 288.1925 - accuracy: 0.0000e+00 - val_loss: 121.1593 - val_accuracy: 0.0000e+00 - 85ms/epoch - 9ms/step\n",
            "Epoch 47/200\n",
            "9/9 - 0s - loss: 305.7147 - accuracy: 0.0000e+00 - val_loss: 88.9038 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 48/200\n",
            "9/9 - 0s - loss: 273.7953 - accuracy: 0.0000e+00 - val_loss: 82.0098 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 49/200\n",
            "9/9 - 0s - loss: 355.2216 - accuracy: 0.0000e+00 - val_loss: 62.2819 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 50/200\n",
            "9/9 - 0s - loss: 284.1558 - accuracy: 0.0000e+00 - val_loss: 132.9924 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 51/200\n",
            "9/9 - 0s - loss: 332.4307 - accuracy: 0.0000e+00 - val_loss: 136.3829 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 52/200\n",
            "9/9 - 0s - loss: 304.4049 - accuracy: 0.0000e+00 - val_loss: 83.9842 - val_accuracy: 0.0000e+00 - 108ms/epoch - 12ms/step\n",
            "Epoch 53/200\n",
            "9/9 - 0s - loss: 334.9419 - accuracy: 0.0000e+00 - val_loss: 72.3124 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 54/200\n",
            "9/9 - 0s - loss: 302.3094 - accuracy: 0.0000e+00 - val_loss: 61.0480 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 55/200\n",
            "9/9 - 0s - loss: 273.8990 - accuracy: 0.0000e+00 - val_loss: 66.6364 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 56/200\n",
            "9/9 - 0s - loss: 306.5142 - accuracy: 0.0000e+00 - val_loss: 72.7320 - val_accuracy: 0.0000e+00 - 84ms/epoch - 9ms/step\n",
            "Epoch 57/200\n",
            "9/9 - 0s - loss: 252.6863 - accuracy: 0.0000e+00 - val_loss: 61.9730 - val_accuracy: 0.0000e+00 - 85ms/epoch - 9ms/step\n",
            "Epoch 58/200\n",
            "9/9 - 0s - loss: 286.1195 - accuracy: 0.0000e+00 - val_loss: 85.9030 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 59/200\n",
            "9/9 - 0s - loss: 260.8726 - accuracy: 0.0000e+00 - val_loss: 63.4782 - val_accuracy: 0.0000e+00 - 87ms/epoch - 10ms/step\n",
            "Epoch 60/200\n",
            "9/9 - 0s - loss: 286.4783 - accuracy: 0.0000e+00 - val_loss: 69.4874 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 61/200\n",
            "9/9 - 0s - loss: 266.1504 - accuracy: 0.0000e+00 - val_loss: 107.0584 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 62/200\n",
            "9/9 - 0s - loss: 386.3308 - accuracy: 0.0000e+00 - val_loss: 59.0870 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 63/200\n",
            "9/9 - 0s - loss: 296.4037 - accuracy: 0.0000e+00 - val_loss: 57.5601 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 64/200\n",
            "9/9 - 0s - loss: 268.6738 - accuracy: 0.0000e+00 - val_loss: 70.2491 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 65/200\n",
            "9/9 - 0s - loss: 306.7997 - accuracy: 0.0000e+00 - val_loss: 57.9152 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 66/200\n",
            "9/9 - 0s - loss: 362.8234 - accuracy: 0.0000e+00 - val_loss: 78.3523 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 67/200\n",
            "9/9 - 0s - loss: 294.6128 - accuracy: 0.0000e+00 - val_loss: 126.4599 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 68/200\n",
            "9/9 - 0s - loss: 301.1843 - accuracy: 0.0000e+00 - val_loss: 55.1977 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 69/200\n",
            "9/9 - 0s - loss: 290.1727 - accuracy: 0.0000e+00 - val_loss: 58.8710 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 70/200\n",
            "9/9 - 0s - loss: 277.5868 - accuracy: 0.0000e+00 - val_loss: 54.3766 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 71/200\n",
            "9/9 - 0s - loss: 279.9111 - accuracy: 0.0000e+00 - val_loss: 58.5200 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 72/200\n",
            "9/9 - 0s - loss: 282.1844 - accuracy: 0.0000e+00 - val_loss: 68.7587 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 73/200\n",
            "9/9 - 0s - loss: 272.7446 - accuracy: 0.0000e+00 - val_loss: 54.5178 - val_accuracy: 0.0000e+00 - 114ms/epoch - 13ms/step\n",
            "Epoch 74/200\n",
            "9/9 - 0s - loss: 300.8548 - accuracy: 0.0000e+00 - val_loss: 59.0267 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 75/200\n",
            "9/9 - 0s - loss: 262.2139 - accuracy: 0.0000e+00 - val_loss: 53.6101 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 76/200\n",
            "9/9 - 0s - loss: 278.0876 - accuracy: 0.0000e+00 - val_loss: 61.0665 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 77/200\n",
            "9/9 - 0s - loss: 309.7721 - accuracy: 0.0000e+00 - val_loss: 55.4446 - val_accuracy: 0.0000e+00 - 102ms/epoch - 11ms/step\n",
            "Epoch 78/200\n",
            "9/9 - 0s - loss: 257.7661 - accuracy: 0.0000e+00 - val_loss: 54.4358 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 79/200\n",
            "9/9 - 0s - loss: 284.8860 - accuracy: 0.0000e+00 - val_loss: 73.5302 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 80/200\n",
            "9/9 - 0s - loss: 274.8887 - accuracy: 0.0000e+00 - val_loss: 54.7126 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 81/200\n",
            "9/9 - 0s - loss: 256.8793 - accuracy: 0.0000e+00 - val_loss: 72.4688 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 82/200\n",
            "9/9 - 0s - loss: 303.1692 - accuracy: 0.0000e+00 - val_loss: 52.0037 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 83/200\n",
            "9/9 - 0s - loss: 241.4647 - accuracy: 0.0000e+00 - val_loss: 56.2808 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 84/200\n",
            "9/9 - 0s - loss: 238.2532 - accuracy: 0.0000e+00 - val_loss: 90.1437 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 85/200\n",
            "9/9 - 0s - loss: 278.1931 - accuracy: 0.0000e+00 - val_loss: 51.8752 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 86/200\n",
            "9/9 - 0s - loss: 271.8543 - accuracy: 0.0000e+00 - val_loss: 51.5257 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 87/200\n",
            "9/9 - 0s - loss: 277.1980 - accuracy: 0.0000e+00 - val_loss: 55.8673 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 88/200\n",
            "9/9 - 0s - loss: 276.2241 - accuracy: 0.0000e+00 - val_loss: 51.4515 - val_accuracy: 0.0000e+00 - 84ms/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "9/9 - 0s - loss: 305.8500 - accuracy: 0.0000e+00 - val_loss: 63.7425 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 90/200\n",
            "9/9 - 0s - loss: 271.8961 - accuracy: 0.0000e+00 - val_loss: 68.2754 - val_accuracy: 0.0000e+00 - 87ms/epoch - 10ms/step\n",
            "Epoch 91/200\n",
            "9/9 - 0s - loss: 280.3431 - accuracy: 0.0000e+00 - val_loss: 61.0118 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 92/200\n",
            "9/9 - 0s - loss: 313.1949 - accuracy: 0.0000e+00 - val_loss: 101.4892 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 93/200\n",
            "9/9 - 0s - loss: 289.6125 - accuracy: 0.0000e+00 - val_loss: 51.2162 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 94/200\n",
            "9/9 - 0s - loss: 289.4782 - accuracy: 0.0000e+00 - val_loss: 51.9248 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 95/200\n",
            "9/9 - 0s - loss: 264.3866 - accuracy: 0.0000e+00 - val_loss: 50.1821 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 96/200\n",
            "9/9 - 0s - loss: 259.9720 - accuracy: 0.0000e+00 - val_loss: 60.0428 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 97/200\n",
            "9/9 - 0s - loss: 315.9093 - accuracy: 0.0000e+00 - val_loss: 80.9074 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 98/200\n",
            "9/9 - 0s - loss: 288.5666 - accuracy: 0.0000e+00 - val_loss: 66.2174 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 99/200\n",
            "9/9 - 0s - loss: 282.7095 - accuracy: 0.0000e+00 - val_loss: 57.8196 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 100/200\n",
            "9/9 - 0s - loss: 286.2028 - accuracy: 0.0000e+00 - val_loss: 55.1920 - val_accuracy: 0.0000e+00 - 90ms/epoch - 10ms/step\n",
            "Epoch 101/200\n",
            "9/9 - 0s - loss: 299.7070 - accuracy: 0.0000e+00 - val_loss: 51.9954 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 102/200\n",
            "9/9 - 0s - loss: 278.8262 - accuracy: 0.0000e+00 - val_loss: 54.3639 - val_accuracy: 0.0000e+00 - 102ms/epoch - 11ms/step\n",
            "Epoch 103/200\n",
            "9/9 - 0s - loss: 280.7637 - accuracy: 0.0000e+00 - val_loss: 48.8188 - val_accuracy: 0.0000e+00 - 107ms/epoch - 12ms/step\n",
            "Epoch 104/200\n",
            "9/9 - 0s - loss: 292.4176 - accuracy: 0.0000e+00 - val_loss: 61.6350 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 105/200\n",
            "9/9 - 0s - loss: 300.9052 - accuracy: 0.0000e+00 - val_loss: 112.2663 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 106/200\n",
            "9/9 - 0s - loss: 283.1744 - accuracy: 0.0000e+00 - val_loss: 162.7664 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 107/200\n",
            "9/9 - 0s - loss: 326.1931 - accuracy: 0.0000e+00 - val_loss: 65.9033 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 108/200\n",
            "9/9 - 0s - loss: 270.2908 - accuracy: 0.0000e+00 - val_loss: 63.7274 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 109/200\n",
            "9/9 - 0s - loss: 289.6975 - accuracy: 0.0000e+00 - val_loss: 48.4132 - val_accuracy: 0.0000e+00 - 86ms/epoch - 10ms/step\n",
            "Epoch 110/200\n",
            "9/9 - 0s - loss: 282.9265 - accuracy: 0.0000e+00 - val_loss: 56.6769 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 111/200\n",
            "9/9 - 0s - loss: 278.2624 - accuracy: 0.0000e+00 - val_loss: 47.4785 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 112/200\n",
            "9/9 - 0s - loss: 366.8240 - accuracy: 0.0000e+00 - val_loss: 47.3308 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 113/200\n",
            "9/9 - 0s - loss: 290.2361 - accuracy: 0.0000e+00 - val_loss: 85.1324 - val_accuracy: 0.0000e+00 - 103ms/epoch - 11ms/step\n",
            "Epoch 114/200\n",
            "9/9 - 0s - loss: 280.1447 - accuracy: 0.0000e+00 - val_loss: 69.3976 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 115/200\n",
            "9/9 - 0s - loss: 315.8817 - accuracy: 0.0000e+00 - val_loss: 55.0804 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 116/200\n",
            "9/9 - 0s - loss: 290.2605 - accuracy: 0.0000e+00 - val_loss: 64.0990 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 117/200\n",
            "9/9 - 0s - loss: 278.7922 - accuracy: 0.0000e+00 - val_loss: 130.0007 - val_accuracy: 0.0000e+00 - 84ms/epoch - 9ms/step\n",
            "Epoch 118/200\n",
            "9/9 - 0s - loss: 334.0329 - accuracy: 0.0000e+00 - val_loss: 130.2409 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 119/200\n",
            "9/9 - 0s - loss: 312.4398 - accuracy: 0.0000e+00 - val_loss: 152.7183 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 120/200\n",
            "9/9 - 0s - loss: 289.4129 - accuracy: 0.0000e+00 - val_loss: 49.1026 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 121/200\n",
            "9/9 - 0s - loss: 272.9562 - accuracy: 0.0000e+00 - val_loss: 51.7087 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 122/200\n",
            "9/9 - 0s - loss: 274.3826 - accuracy: 0.0000e+00 - val_loss: 52.5560 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 123/200\n",
            "9/9 - 0s - loss: 279.2979 - accuracy: 0.0000e+00 - val_loss: 51.3402 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 124/200\n",
            "9/9 - 0s - loss: 261.5448 - accuracy: 0.0000e+00 - val_loss: 46.7212 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 125/200\n",
            "9/9 - 0s - loss: 264.0402 - accuracy: 0.0000e+00 - val_loss: 48.4159 - val_accuracy: 0.0000e+00 - 122ms/epoch - 14ms/step\n",
            "Epoch 126/200\n",
            "9/9 - 0s - loss: 313.2588 - accuracy: 0.0000e+00 - val_loss: 52.0602 - val_accuracy: 0.0000e+00 - 119ms/epoch - 13ms/step\n",
            "Epoch 127/200\n",
            "9/9 - 0s - loss: 243.0206 - accuracy: 0.0000e+00 - val_loss: 49.0000 - val_accuracy: 0.0000e+00 - 110ms/epoch - 12ms/step\n",
            "Epoch 128/200\n",
            "9/9 - 0s - loss: 283.4934 - accuracy: 0.0000e+00 - val_loss: 45.8094 - val_accuracy: 0.0000e+00 - 114ms/epoch - 13ms/step\n",
            "Epoch 129/200\n",
            "9/9 - 0s - loss: 298.0436 - accuracy: 0.0000e+00 - val_loss: 48.3630 - val_accuracy: 0.0000e+00 - 109ms/epoch - 12ms/step\n",
            "Epoch 130/200\n",
            "9/9 - 0s - loss: 260.0149 - accuracy: 0.0000e+00 - val_loss: 46.5212 - val_accuracy: 0.0000e+00 - 112ms/epoch - 12ms/step\n",
            "Epoch 131/200\n",
            "9/9 - 0s - loss: 283.4453 - accuracy: 0.0000e+00 - val_loss: 45.9307 - val_accuracy: 0.0000e+00 - 109ms/epoch - 12ms/step\n",
            "Epoch 132/200\n",
            "9/9 - 0s - loss: 268.6549 - accuracy: 0.0000e+00 - val_loss: 71.9083 - val_accuracy: 0.0000e+00 - 106ms/epoch - 12ms/step\n",
            "Epoch 133/200\n",
            "9/9 - 0s - loss: 283.1731 - accuracy: 0.0000e+00 - val_loss: 53.4612 - val_accuracy: 0.0000e+00 - 116ms/epoch - 13ms/step\n",
            "Epoch 134/200\n",
            "9/9 - 0s - loss: 275.8935 - accuracy: 0.0000e+00 - val_loss: 78.1462 - val_accuracy: 0.0000e+00 - 114ms/epoch - 13ms/step\n",
            "Epoch 135/200\n",
            "9/9 - 0s - loss: 276.2899 - accuracy: 0.0000e+00 - val_loss: 54.1912 - val_accuracy: 0.0000e+00 - 108ms/epoch - 12ms/step\n",
            "Epoch 136/200\n",
            "9/9 - 0s - loss: 295.2833 - accuracy: 0.0000e+00 - val_loss: 45.6949 - val_accuracy: 0.0000e+00 - 107ms/epoch - 12ms/step\n",
            "Epoch 137/200\n",
            "9/9 - 0s - loss: 252.1901 - accuracy: 0.0000e+00 - val_loss: 67.0663 - val_accuracy: 0.0000e+00 - 109ms/epoch - 12ms/step\n",
            "Epoch 138/200\n",
            "9/9 - 0s - loss: 290.1361 - accuracy: 0.0000e+00 - val_loss: 84.8904 - val_accuracy: 0.0000e+00 - 115ms/epoch - 13ms/step\n",
            "Epoch 139/200\n",
            "9/9 - 0s - loss: 282.0893 - accuracy: 0.0000e+00 - val_loss: 47.7229 - val_accuracy: 0.0000e+00 - 119ms/epoch - 13ms/step\n",
            "Epoch 140/200\n",
            "9/9 - 0s - loss: 272.5350 - accuracy: 0.0000e+00 - val_loss: 47.2376 - val_accuracy: 0.0000e+00 - 119ms/epoch - 13ms/step\n",
            "Epoch 141/200\n",
            "9/9 - 0s - loss: 302.3390 - accuracy: 0.0000e+00 - val_loss: 46.6617 - val_accuracy: 0.0000e+00 - 115ms/epoch - 13ms/step\n",
            "Epoch 142/200\n",
            "9/9 - 0s - loss: 266.0552 - accuracy: 0.0000e+00 - val_loss: 70.3920 - val_accuracy: 0.0000e+00 - 159ms/epoch - 18ms/step\n",
            "Epoch 143/200\n",
            "9/9 - 0s - loss: 263.1905 - accuracy: 0.0000e+00 - val_loss: 46.5110 - val_accuracy: 0.0000e+00 - 116ms/epoch - 13ms/step\n",
            "Epoch 144/200\n",
            "9/9 - 0s - loss: 293.9828 - accuracy: 0.0000e+00 - val_loss: 65.1587 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 145/200\n",
            "9/9 - 0s - loss: 359.4248 - accuracy: 0.0000e+00 - val_loss: 152.6080 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 146/200\n",
            "9/9 - 0s - loss: 345.0252 - accuracy: 0.0000e+00 - val_loss: 79.8325 - val_accuracy: 0.0000e+00 - 84ms/epoch - 9ms/step\n",
            "Epoch 147/200\n",
            "9/9 - 0s - loss: 297.6759 - accuracy: 0.0000e+00 - val_loss: 67.1218 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 148/200\n",
            "9/9 - 0s - loss: 302.6905 - accuracy: 0.0000e+00 - val_loss: 106.7447 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 149/200\n",
            "9/9 - 0s - loss: 274.0066 - accuracy: 0.0000e+00 - val_loss: 64.0906 - val_accuracy: 0.0000e+00 - 99ms/epoch - 11ms/step\n",
            "Epoch 150/200\n",
            "9/9 - 0s - loss: 256.1522 - accuracy: 0.0000e+00 - val_loss: 49.1157 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 151/200\n",
            "9/9 - 0s - loss: 287.1775 - accuracy: 0.0000e+00 - val_loss: 61.2824 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 152/200\n",
            "9/9 - 0s - loss: 253.0255 - accuracy: 0.0000e+00 - val_loss: 45.4802 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 153/200\n",
            "9/9 - 0s - loss: 346.7966 - accuracy: 0.0000e+00 - val_loss: 64.8460 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 154/200\n",
            "9/9 - 0s - loss: 251.2877 - accuracy: 0.0000e+00 - val_loss: 53.9734 - val_accuracy: 0.0000e+00 - 90ms/epoch - 10ms/step\n",
            "Epoch 155/200\n",
            "9/9 - 0s - loss: 251.2674 - accuracy: 0.0000e+00 - val_loss: 53.3534 - val_accuracy: 0.0000e+00 - 87ms/epoch - 10ms/step\n",
            "Epoch 156/200\n",
            "9/9 - 0s - loss: 286.3304 - accuracy: 0.0000e+00 - val_loss: 86.3155 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 157/200\n",
            "9/9 - 0s - loss: 287.0121 - accuracy: 0.0000e+00 - val_loss: 46.6051 - val_accuracy: 0.0000e+00 - 92ms/epoch - 10ms/step\n",
            "Epoch 158/200\n",
            "9/9 - 0s - loss: 316.6763 - accuracy: 0.0000e+00 - val_loss: 49.4435 - val_accuracy: 0.0000e+00 - 99ms/epoch - 11ms/step\n",
            "Epoch 159/200\n",
            "9/9 - 0s - loss: 290.0043 - accuracy: 0.0000e+00 - val_loss: 43.9324 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 160/200\n",
            "9/9 - 0s - loss: 255.7962 - accuracy: 0.0000e+00 - val_loss: 78.2087 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 161/200\n",
            "9/9 - 0s - loss: 282.6797 - accuracy: 0.0000e+00 - val_loss: 43.6731 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 162/200\n",
            "9/9 - 0s - loss: 292.8192 - accuracy: 0.0000e+00 - val_loss: 55.1130 - val_accuracy: 0.0000e+00 - 89ms/epoch - 10ms/step\n",
            "Epoch 163/200\n",
            "9/9 - 0s - loss: 285.6998 - accuracy: 0.0000e+00 - val_loss: 45.7707 - val_accuracy: 0.0000e+00 - 91ms/epoch - 10ms/step\n",
            "Epoch 164/200\n",
            "9/9 - 0s - loss: 277.4950 - accuracy: 0.0000e+00 - val_loss: 70.2738 - val_accuracy: 0.0000e+00 - 99ms/epoch - 11ms/step\n",
            "Epoch 165/200\n",
            "9/9 - 0s - loss: 250.1942 - accuracy: 0.0000e+00 - val_loss: 43.9227 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 166/200\n",
            "9/9 - 0s - loss: 271.6521 - accuracy: 0.0000e+00 - val_loss: 71.3994 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 167/200\n",
            "9/9 - 0s - loss: 289.4377 - accuracy: 0.0000e+00 - val_loss: 85.2742 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 168/200\n",
            "9/9 - 0s - loss: 279.4782 - accuracy: 0.0000e+00 - val_loss: 134.2178 - val_accuracy: 0.0000e+00 - 94ms/epoch - 10ms/step\n",
            "Epoch 169/200\n",
            "9/9 - 0s - loss: 321.7825 - accuracy: 0.0000e+00 - val_loss: 104.9694 - val_accuracy: 0.0000e+00 - 99ms/epoch - 11ms/step\n",
            "Epoch 170/200\n",
            "9/9 - 0s - loss: 348.2701 - accuracy: 0.0000e+00 - val_loss: 58.9825 - val_accuracy: 0.0000e+00 - 86ms/epoch - 10ms/step\n",
            "Epoch 171/200\n",
            "9/9 - 0s - loss: 310.2659 - accuracy: 0.0000e+00 - val_loss: 62.1645 - val_accuracy: 0.0000e+00 - 120ms/epoch - 13ms/step\n",
            "Epoch 172/200\n",
            "9/9 - 0s - loss: 305.4717 - accuracy: 0.0000e+00 - val_loss: 60.2468 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 173/200\n",
            "9/9 - 0s - loss: 290.8606 - accuracy: 0.0000e+00 - val_loss: 63.8678 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 174/200\n",
            "9/9 - 0s - loss: 278.2947 - accuracy: 0.0000e+00 - val_loss: 46.1827 - val_accuracy: 0.0000e+00 - 88ms/epoch - 10ms/step\n",
            "Epoch 175/200\n",
            "9/9 - 0s - loss: 245.0018 - accuracy: 0.0000e+00 - val_loss: 59.8777 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 176/200\n",
            "9/9 - 0s - loss: 294.2863 - accuracy: 0.0000e+00 - val_loss: 43.8572 - val_accuracy: 0.0000e+00 - 98ms/epoch - 11ms/step\n",
            "Epoch 177/200\n",
            "9/9 - 0s - loss: 268.2976 - accuracy: 0.0000e+00 - val_loss: 62.9847 - val_accuracy: 0.0000e+00 - 86ms/epoch - 10ms/step\n",
            "Epoch 178/200\n",
            "9/9 - 0s - loss: 272.4869 - accuracy: 0.0000e+00 - val_loss: 72.1183 - val_accuracy: 0.0000e+00 - 99ms/epoch - 11ms/step\n",
            "Epoch 179/200\n",
            "9/9 - 0s - loss: 247.6585 - accuracy: 0.0000e+00 - val_loss: 58.6796 - val_accuracy: 0.0000e+00 - 101ms/epoch - 11ms/step\n",
            "Epoch 180/200\n",
            "9/9 - 0s - loss: 308.7067 - accuracy: 0.0000e+00 - val_loss: 44.9744 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 181/200\n",
            "9/9 - 0s - loss: 268.4641 - accuracy: 0.0000e+00 - val_loss: 47.1794 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 182/200\n",
            "9/9 - 0s - loss: 268.7544 - accuracy: 0.0000e+00 - val_loss: 75.7444 - val_accuracy: 0.0000e+00 - 103ms/epoch - 11ms/step\n",
            "Epoch 183/200\n",
            "9/9 - 0s - loss: 274.1053 - accuracy: 0.0000e+00 - val_loss: 54.1898 - val_accuracy: 0.0000e+00 - 87ms/epoch - 10ms/step\n",
            "Epoch 184/200\n",
            "9/9 - 0s - loss: 290.5708 - accuracy: 0.0000e+00 - val_loss: 82.9506 - val_accuracy: 0.0000e+00 - 90ms/epoch - 10ms/step\n",
            "Epoch 185/200\n",
            "9/9 - 0s - loss: 262.2134 - accuracy: 0.0000e+00 - val_loss: 59.0107 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 186/200\n",
            "9/9 - 0s - loss: 326.8455 - accuracy: 0.0000e+00 - val_loss: 102.2557 - val_accuracy: 0.0000e+00 - 93ms/epoch - 10ms/step\n",
            "Epoch 187/200\n",
            "9/9 - 0s - loss: 279.4741 - accuracy: 0.0000e+00 - val_loss: 72.3903 - val_accuracy: 0.0000e+00 - 102ms/epoch - 11ms/step\n",
            "Epoch 188/200\n",
            "9/9 - 0s - loss: 315.5918 - accuracy: 0.0000e+00 - val_loss: 42.1717 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 189/200\n",
            "9/9 - 0s - loss: 268.0832 - accuracy: 0.0000e+00 - val_loss: 71.8253 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 190/200\n",
            "9/9 - 0s - loss: 270.6953 - accuracy: 0.0000e+00 - val_loss: 59.7296 - val_accuracy: 0.0000e+00 - 97ms/epoch - 11ms/step\n",
            "Epoch 191/200\n",
            "9/9 - 0s - loss: 263.5576 - accuracy: 0.0000e+00 - val_loss: 65.3653 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 192/200\n",
            "9/9 - 0s - loss: 269.5111 - accuracy: 0.0000e+00 - val_loss: 50.1760 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 193/200\n",
            "9/9 - 0s - loss: 273.4699 - accuracy: 0.0000e+00 - val_loss: 65.8265 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 194/200\n",
            "9/9 - 0s - loss: 255.2807 - accuracy: 0.0000e+00 - val_loss: 42.6590 - val_accuracy: 0.0000e+00 - 96ms/epoch - 11ms/step\n",
            "Epoch 195/200\n",
            "9/9 - 0s - loss: 276.6894 - accuracy: 0.0000e+00 - val_loss: 92.2761 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "Epoch 196/200\n",
            "9/9 - 0s - loss: 255.7491 - accuracy: 0.0000e+00 - val_loss: 60.3667 - val_accuracy: 0.0000e+00 - 99ms/epoch - 11ms/step\n",
            "Epoch 197/200\n",
            "9/9 - 0s - loss: 275.3554 - accuracy: 0.0000e+00 - val_loss: 42.1629 - val_accuracy: 0.0000e+00 - 90ms/epoch - 10ms/step\n",
            "Epoch 198/200\n",
            "9/9 - 0s - loss: 267.0279 - accuracy: 0.0000e+00 - val_loss: 76.4886 - val_accuracy: 0.0000e+00 - 86ms/epoch - 10ms/step\n",
            "Epoch 199/200\n",
            "9/9 - 0s - loss: 286.2483 - accuracy: 0.0000e+00 - val_loss: 41.0713 - val_accuracy: 0.0000e+00 - 100ms/epoch - 11ms/step\n",
            "Epoch 200/200\n",
            "9/9 - 0s - loss: 258.2123 - accuracy: 0.0000e+00 - val_loss: 44.1481 - val_accuracy: 0.0000e+00 - 95ms/epoch - 11ms/step\n",
            "30/30 [==============================] - 0s 3ms/step\n",
            "Score (RMSE): 6.644401616892875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 0:00:22.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhYc2YgaiV_3",
        "outputId": "4c1292bc-453e-41de-90ef-c9157098f709"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[303.6691   ]\n",
            " [ 13.353323 ]\n",
            " [  8.872517 ]\n",
            " [  1.9291016]\n",
            " [ 21.634398 ]\n",
            " [  1.7921014]\n",
            " [  1.8360586]\n",
            " [ 14.335604 ]\n",
            " [  1.7034341]\n",
            " [288.59158  ]\n",
            " [241.49683  ]\n",
            " [237.98242  ]\n",
            " [  1.7369033]\n",
            " [346.97708  ]\n",
            " [ 21.659948 ]\n",
            " [ 13.75494  ]\n",
            " [ 17.236578 ]\n",
            " [ 13.475241 ]\n",
            " [  1.8573307]\n",
            " [  7.5544553]\n",
            " [230.28932  ]\n",
            " [200.65182  ]\n",
            " [  1.7208565]\n",
            " [  2.3479676]\n",
            " [ 20.840515 ]\n",
            " [  1.8010502]\n",
            " [  9.143413 ]\n",
            " [292.30865  ]\n",
            " [ 16.20877  ]\n",
            " [318.07178  ]\n",
            " [ 10.882114 ]\n",
            " [ 11.297227 ]\n",
            " [  1.8144077]\n",
            " [  1.7333544]\n",
            " [ 15.570618 ]\n",
            " [185.00684  ]\n",
            " [  1.7444651]\n",
            " [  1.8257972]\n",
            " [321.0395   ]\n",
            " [ 59.80988  ]\n",
            " [ 16.663578 ]\n",
            " [ 22.066347 ]\n",
            " [ 18.466698 ]\n",
            " [ 97.7322   ]\n",
            " [  1.6819471]\n",
            " [ 15.304576 ]\n",
            " [ 14.428585 ]\n",
            " [ 18.54329  ]\n",
            " [  1.8682203]\n",
            " [ 14.529461 ]\n",
            " [ 11.458304 ]\n",
            " [ 12.52636  ]\n",
            " [ 20.436579 ]\n",
            " [233.39069  ]\n",
            " [ 46.510906 ]\n",
            " [ 17.616941 ]\n",
            " [ 11.690437 ]\n",
            " [  1.7979965]\n",
            " [344.83554  ]\n",
            " [  1.7959872]\n",
            " [  1.6399873]\n",
            " [ 14.412493 ]\n",
            " [ 15.960297 ]\n",
            " [217.82849  ]\n",
            " [  1.8543751]\n",
            " [ 12.193315 ]\n",
            " [ 46.302395 ]\n",
            " [ 13.888825 ]\n",
            " [ 45.508762 ]\n",
            " [  1.7983141]\n",
            " [ 13.444198 ]\n",
            " [ 14.50744  ]\n",
            " [ 18.538586 ]\n",
            " [  1.8126107]\n",
            " [ 14.168605 ]\n",
            " [  1.7200392]\n",
            " [ 12.472502 ]\n",
            " [ 20.284946 ]\n",
            " [210.48245  ]\n",
            " [ 12.726673 ]\n",
            " [234.57033  ]\n",
            " [  1.779562 ]\n",
            " [ 19.532856 ]\n",
            " [242.58008  ]\n",
            " [  1.6775467]\n",
            " [  1.7183213]\n",
            " [ 12.582853 ]\n",
            " [ 15.936851 ]\n",
            " [ 12.729584 ]\n",
            " [  1.6741501]\n",
            " [ 17.75552  ]\n",
            " [ 18.860258 ]\n",
            " [  1.7653892]\n",
            " [  1.6807052]\n",
            " [ 14.751311 ]\n",
            " [277.09515  ]\n",
            " [  1.6830065]\n",
            " [ 17.360716 ]\n",
            " [ 15.800987 ]\n",
            " [233.437    ]\n",
            " [ 19.254198 ]\n",
            " [  1.9066609]\n",
            " [ 18.907196 ]\n",
            " [288.678    ]\n",
            " [ 31.495663 ]\n",
            " [  1.7771616]\n",
            " [  1.9442388]\n",
            " [ 16.48233  ]\n",
            " [  9.930714 ]\n",
            " [272.58014  ]\n",
            " [  1.7708467]\n",
            " [  1.6782001]\n",
            " [ 18.4961   ]\n",
            " [ 29.384556 ]\n",
            " [  1.9236789]\n",
            " [  1.705222 ]\n",
            " [292.13885  ]\n",
            " [ 15.121185 ]\n",
            " [ 15.787231 ]\n",
            " [  1.7614328]\n",
            " [ 15.31812  ]\n",
            " [  1.8231063]\n",
            " [ 21.465723 ]\n",
            " [151.22954  ]\n",
            " [ 21.945528 ]\n",
            " [  3.2209883]\n",
            " [288.93488  ]\n",
            " [ 13.962987 ]\n",
            " [  2.045117 ]\n",
            " [ 13.730241 ]\n",
            " [256.033    ]\n",
            " [ 21.20301  ]\n",
            " [ 21.118305 ]\n",
            " [ 16.630865 ]\n",
            " [  9.339346 ]\n",
            " [ 13.839895 ]\n",
            " [ 19.850544 ]\n",
            " [ 19.344748 ]\n",
            " [ 13.816594 ]\n",
            " [  1.7600425]\n",
            " [  1.8017988]\n",
            " [  1.735603 ]\n",
            " [  1.6933421]\n",
            " [  4.1588416]\n",
            " [  1.6466357]\n",
            " [ 13.546921 ]\n",
            " [ 13.638192 ]\n",
            " [ 11.571796 ]\n",
            " [ 13.165187 ]\n",
            " [ 10.491136 ]\n",
            " [219.07196  ]\n",
            " [  2.1425796]\n",
            " [ 16.003023 ]\n",
            " [ 23.074131 ]\n",
            " [ 14.981335 ]\n",
            " [  1.9017203]\n",
            " [  1.7014939]\n",
            " [ 22.478907 ]\n",
            " [ 19.943472 ]\n",
            " [  1.743948 ]\n",
            " [354.06378  ]\n",
            " [  7.254541 ]\n",
            " [294.41068  ]\n",
            " [270.7792   ]\n",
            " [166.76266  ]\n",
            " [ 13.754645 ]\n",
            " [  9.907876 ]\n",
            " [  1.7259374]\n",
            " [222.42447  ]\n",
            " [ 12.825687 ]\n",
            " [110.71698  ]\n",
            " [  1.7695619]\n",
            " [ 18.903385 ]\n",
            " [  1.8253671]\n",
            " [ 12.781044 ]\n",
            " [ 19.389051 ]\n",
            " [  1.8383696]\n",
            " [ 20.842794 ]\n",
            " [ 15.880427 ]\n",
            " [  1.8315178]\n",
            " [  1.7826297]\n",
            " [198.07616  ]\n",
            " [ 12.170929 ]\n",
            " [  1.8395935]\n",
            " [ 14.502834 ]\n",
            " [  1.6992913]\n",
            " [  1.7851504]\n",
            " [136.4265   ]\n",
            " [  2.00662  ]\n",
            " [  1.7038721]\n",
            " [210.37462  ]\n",
            " [  1.6747727]\n",
            " [250.87088  ]\n",
            " [ 18.564823 ]\n",
            " [  2.4853737]\n",
            " [  1.7556975]\n",
            " [  2.1750793]\n",
            " [ 10.736017 ]\n",
            " [345.88654  ]\n",
            " [  1.7576197]\n",
            " [  1.9554539]\n",
            " [ 14.905453 ]\n",
            " [ 19.847025 ]\n",
            " [ 22.367142 ]\n",
            " [ 13.981397 ]\n",
            " [ 15.789784 ]\n",
            " [274.0402   ]\n",
            " [ 19.306358 ]\n",
            " [  2.8211865]\n",
            " [ 16.188454 ]\n",
            " [ 15.865799 ]\n",
            " [ 21.395416 ]\n",
            " [ 11.003829 ]\n",
            " [ 14.041035 ]\n",
            " [ 14.533947 ]\n",
            " [ 13.1940565]\n",
            " [ 19.271118 ]\n",
            " [  1.728192 ]\n",
            " [  6.8105526]\n",
            " [ 14.421309 ]\n",
            " [  1.8005438]\n",
            " [  1.7410033]\n",
            " [  1.6205245]\n",
            " [  9.055604 ]\n",
            " [132.19931  ]\n",
            " [  1.6592108]\n",
            " [  1.9971827]\n",
            " [ 15.322533 ]\n",
            " [ 21.123642 ]\n",
            " [ 20.317556 ]\n",
            " [281.9315   ]\n",
            " [  1.5957122]\n",
            " [ 21.12427  ]\n",
            " [ 99.83235  ]\n",
            " [ 16.501957 ]\n",
            " [  1.6625488]\n",
            " [  2.8584957]\n",
            " [236.8292   ]\n",
            " [  1.9759365]\n",
            " [  1.6940262]\n",
            " [ 19.597675 ]\n",
            " [ 50.228924 ]\n",
            " [249.86609  ]\n",
            " [ 13.454092 ]\n",
            " [ 18.188543 ]\n",
            " [ 12.215712 ]\n",
            " [ 16.183327 ]\n",
            " [146.08437  ]\n",
            " [ 16.055231 ]\n",
            " [192.80533  ]\n",
            " [ 20.87041  ]\n",
            " [ 19.32721  ]\n",
            " [  1.7948196]\n",
            " [  1.7380728]\n",
            " [ 13.977012 ]\n",
            " [ 13.813114 ]\n",
            " [147.13321  ]\n",
            " [338.37668  ]\n",
            " [285.98303  ]\n",
            " [ 17.265326 ]\n",
            " [  1.8291968]\n",
            " [ 45.914116 ]\n",
            " [273.1808   ]\n",
            " [ 13.267656 ]\n",
            " [  2.706661 ]\n",
            " [ 12.55571  ]\n",
            " [359.64633  ]\n",
            " [  1.9341149]\n",
            " [  1.8107009]\n",
            " [ 12.954292 ]\n",
            " [ 11.645164 ]\n",
            " [ 19.840435 ]\n",
            " [  1.8915254]\n",
            " [201.31529  ]\n",
            " [ 14.601372 ]\n",
            " [221.8372   ]\n",
            " [ 13.344091 ]\n",
            " [213.12885  ]\n",
            " [197.34431  ]\n",
            " [ 19.317963 ]\n",
            " [ 20.683874 ]\n",
            " [  1.7846252]\n",
            " [ 11.546023 ]\n",
            " [  1.909531 ]\n",
            " [ 21.777372 ]\n",
            " [ 13.002869 ]\n",
            " [ 21.015934 ]\n",
            " [183.58766  ]\n",
            " [ 20.808638 ]\n",
            " [ 19.02957  ]\n",
            " [118.357    ]\n",
            " [ 11.317178 ]\n",
            " [  1.7522095]\n",
            " [  1.7123512]\n",
            " [ 19.41417  ]\n",
            " [  1.6953232]\n",
            " [  1.7877156]\n",
            " [ 14.980162 ]\n",
            " [ 14.058014 ]\n",
            " [274.01636  ]\n",
            " [213.97768  ]\n",
            " [ 18.902372 ]\n",
            " [ 12.118978 ]\n",
            " [ 10.773153 ]\n",
            " [220.86809  ]\n",
            " [ 13.344773 ]\n",
            " [  1.7913132]\n",
            " [212.28407  ]\n",
            " [ 12.675009 ]\n",
            " [  1.7259518]\n",
            " [ 21.671318 ]\n",
            " [ 11.501676 ]\n",
            " [ 22.525757 ]\n",
            " [167.43622  ]\n",
            " [  6.2192464]\n",
            " [  1.7991639]\n",
            " [ 17.958084 ]\n",
            " [  1.7280015]\n",
            " [ 14.3109665]\n",
            " [  1.7550542]\n",
            " [358.59756  ]\n",
            " [  1.6180847]\n",
            " [ 14.997846 ]\n",
            " [218.98239  ]\n",
            " [220.88159  ]\n",
            " [ 13.184355 ]\n",
            " [ 13.360033 ]\n",
            " [ 19.519627 ]\n",
            " [ 21.467266 ]\n",
            " [208.22717  ]\n",
            " [ 13.409879 ]\n",
            " [ 15.55047  ]\n",
            " [  1.6428014]\n",
            " [ 15.576474 ]\n",
            " [ 20.708565 ]\n",
            " [340.5214   ]\n",
            " [ 17.864265 ]\n",
            " [ 18.480564 ]\n",
            " [ 15.336677 ]\n",
            " [ 21.878477 ]\n",
            " [  8.28035  ]\n",
            " [  1.7403755]\n",
            " [ 19.146666 ]\n",
            " [197.23433  ]\n",
            " [ 22.085585 ]\n",
            " [  1.680535 ]\n",
            " [184.248    ]\n",
            " [ 17.54933  ]\n",
            " [ 21.475534 ]\n",
            " [  1.6531011]\n",
            " [ 16.004732 ]\n",
            " [  1.7289336]\n",
            " [ 14.630418 ]\n",
            " [ 22.90432  ]\n",
            " [ 22.090029 ]\n",
            " [ 12.379034 ]\n",
            " [267.8849   ]\n",
            " [320.03384  ]\n",
            " [  1.9942137]\n",
            " [ 17.954065 ]\n",
            " [132.77582  ]\n",
            " [  1.663355 ]\n",
            " [  2.3387399]\n",
            " [187.43513  ]\n",
            " [ 11.040167 ]\n",
            " [  2.0701447]\n",
            " [ 16.392544 ]\n",
            " [  1.8231964]\n",
            " [277.58142  ]\n",
            " [122.53055  ]\n",
            " [ 32.29266  ]\n",
            " [209.03336  ]\n",
            " [ 13.103378 ]\n",
            " [ 15.031407 ]\n",
            " [ 10.413471 ]\n",
            " [ 14.241701 ]\n",
            " [ 14.215571 ]\n",
            " [ 13.864829 ]\n",
            " [  6.3394594]\n",
            " [  1.7138497]\n",
            " [ 13.444661 ]\n",
            " [331.96866  ]\n",
            " [  7.9097714]\n",
            " [ 15.185053 ]\n",
            " [ 14.600829 ]\n",
            " [ 13.756125 ]\n",
            " [ 22.383926 ]\n",
            " [236.10509  ]\n",
            " [  1.7198118]\n",
            " [ 14.768135 ]\n",
            " [ 12.695224 ]\n",
            " [ 17.086367 ]\n",
            " [ 13.15323  ]\n",
            " [  1.8484269]\n",
            " [199.96776  ]\n",
            " [ 14.066771 ]\n",
            " [  1.8358169]\n",
            " [ 20.795458 ]\n",
            " [  1.8128567]\n",
            " [ 12.47561  ]\n",
            " [341.42673  ]\n",
            " [  1.7754567]\n",
            " [ 15.695921 ]\n",
            " [217.63214  ]\n",
            " [ 19.86472  ]\n",
            " [ 16.991531 ]\n",
            " [215.7117   ]\n",
            " [290.1908   ]\n",
            " [ 15.670367 ]\n",
            " [  1.771164 ]\n",
            " [ 16.481693 ]\n",
            " [ 19.475643 ]\n",
            " [ 47.2318   ]\n",
            " [  1.7697132]\n",
            " [ 12.75486  ]\n",
            " [ 22.457586 ]\n",
            " [ 13.801735 ]\n",
            " [282.14108  ]\n",
            " [ 17.269672 ]\n",
            " [139.35704  ]\n",
            " [ 14.638936 ]\n",
            " [ 13.503788 ]\n",
            " [ 17.538723 ]\n",
            " [ 12.869566 ]\n",
            " [ 14.308026 ]\n",
            " [ 19.36702  ]\n",
            " [  2.0130486]\n",
            " [ 15.034861 ]\n",
            " [  1.79988  ]\n",
            " [  1.702936 ]\n",
            " [290.65558  ]\n",
            " [ 15.695389 ]\n",
            " [ 12.049537 ]\n",
            " [251.25754  ]\n",
            " [  9.519339 ]\n",
            " [ 18.558386 ]\n",
            " [ 23.427103 ]\n",
            " [  1.6996446]\n",
            " [ 15.211829 ]\n",
            " [ 15.311243 ]\n",
            " [215.6171   ]\n",
            " [ 12.913701 ]\n",
            " [  1.7817204]\n",
            " [ 49.51018  ]\n",
            " [193.52066  ]\n",
            " [ 14.293708 ]\n",
            " [ 13.698841 ]\n",
            " [ 52.740376 ]\n",
            " [  1.9194628]\n",
            " [  1.7720176]\n",
            " [ 18.995272 ]\n",
            " [ 12.655323 ]\n",
            " [ 19.593872 ]\n",
            " [  1.9007549]\n",
            " [  1.7476037]\n",
            " [ 20.79168  ]\n",
            " [ 22.193132 ]\n",
            " [ 12.657381 ]\n",
            " [ 56.63317  ]\n",
            " [ 14.899593 ]\n",
            " [ 22.146757 ]\n",
            " [ 15.200343 ]\n",
            " [ 16.014994 ]\n",
            " [195.80869  ]\n",
            " [ 12.603796 ]\n",
            " [ 15.699881 ]\n",
            " [ 15.801958 ]\n",
            " [  1.6353831]\n",
            " [256.33282  ]\n",
            " [195.26183  ]\n",
            " [338.87863  ]\n",
            " [ 15.443541 ]\n",
            " [  1.6947342]\n",
            " [ 20.205471 ]\n",
            " [  1.6899633]\n",
            " [  1.7756037]\n",
            " [234.22328  ]\n",
            " [ 15.7645235]\n",
            " [  1.7744577]\n",
            " [ 16.671183 ]\n",
            " [ 16.360746 ]\n",
            " [ 14.398229 ]\n",
            " [  1.7921021]\n",
            " [ 20.819937 ]\n",
            " [229.46591  ]\n",
            " [ 13.512272 ]\n",
            " [  1.7015988]\n",
            " [ 12.111732 ]\n",
            " [  1.8092355]\n",
            " [ 19.093073 ]\n",
            " [  1.6951606]\n",
            " [  1.8249767]\n",
            " [  1.6789249]\n",
            " [ 14.133563 ]\n",
            " [  8.893438 ]\n",
            " [ 18.065271 ]\n",
            " [224.3728   ]\n",
            " [ 20.346727 ]\n",
            " [171.90417  ]\n",
            " [ 21.741835 ]\n",
            " [213.86552  ]\n",
            " [ 13.610771 ]\n",
            " [ 12.623039 ]\n",
            " [  1.7566509]\n",
            " [ 21.107883 ]\n",
            " [ 13.801881 ]\n",
            " [186.4028   ]\n",
            " [  1.8153018]\n",
            " [204.0946   ]\n",
            " [  1.9805801]\n",
            " [ 65.45716  ]\n",
            " [  1.8609978]\n",
            " [235.54863  ]\n",
            " [ 15.219142 ]\n",
            " [ 15.794337 ]\n",
            " [329.05823  ]\n",
            " [  6.213498 ]\n",
            " [ 13.894792 ]\n",
            " [ 19.84483  ]\n",
            " [385.00983  ]\n",
            " [ 22.76567  ]\n",
            " [ 12.344051 ]\n",
            " [ 46.07041  ]\n",
            " [ 19.833641 ]\n",
            " [ 21.49884  ]\n",
            " [ 16.633518 ]\n",
            " [ 14.780085 ]\n",
            " [ 11.529468 ]\n",
            " [ 14.000791 ]\n",
            " [ 15.847979 ]\n",
            " [ 52.665062 ]\n",
            " [181.8646   ]\n",
            " [261.0919   ]\n",
            " [ 13.012121 ]\n",
            " [205.77315  ]\n",
            " [269.59534  ]\n",
            " [ 15.712829 ]\n",
            " [ 12.022325 ]\n",
            " [ 23.189394 ]\n",
            " [ 11.073431 ]\n",
            " [ 11.606341 ]\n",
            " [143.43224  ]\n",
            " [ 14.368728 ]\n",
            " [200.96236  ]\n",
            " [  1.8346671]\n",
            " [ 16.296339 ]\n",
            " [ 15.115837 ]\n",
            " [  1.7619374]\n",
            " [ 14.208672 ]\n",
            " [  2.269898 ]\n",
            " [ 15.141958 ]\n",
            " [220.4026   ]\n",
            " [  7.831431 ]\n",
            " [ 13.107828 ]\n",
            " [ 14.248156 ]\n",
            " [ 14.2940445]\n",
            " [ 96.68159  ]\n",
            " [348.85263  ]\n",
            " [ 13.404845 ]\n",
            " [ 13.450478 ]\n",
            " [  2.0521886]\n",
            " [  1.9635298]\n",
            " [  1.7579615]\n",
            " [  1.6700745]\n",
            " [ 18.584799 ]\n",
            " [321.1871   ]\n",
            " [ 19.373264 ]\n",
            " [  1.8052534]\n",
            " [  2.233024 ]\n",
            " [173.47055  ]\n",
            " [ 12.134058 ]\n",
            " [  1.7295169]\n",
            " [ 20.93776  ]\n",
            " [282.0673   ]\n",
            " [212.45912  ]\n",
            " [ 12.847314 ]\n",
            " [ 14.882723 ]\n",
            " [ 12.785168 ]\n",
            " [  1.6938219]\n",
            " [251.2146   ]\n",
            " [ 18.384474 ]\n",
            " [  2.1176505]\n",
            " [ 20.823809 ]\n",
            " [360.55508  ]\n",
            " [  1.7060621]\n",
            " [ 15.731099 ]\n",
            " [  2.1262941]\n",
            " [  1.7110726]\n",
            " [  2.0188358]\n",
            " [ 22.294275 ]\n",
            " [  7.81748  ]\n",
            " [ 19.069025 ]\n",
            " [  1.7151843]\n",
            " [ 15.52612  ]\n",
            " [ 10.825563 ]\n",
            " [ 21.053673 ]\n",
            " [ 11.421716 ]\n",
            " [ 16.876217 ]\n",
            " [  1.7780136]\n",
            " [ 13.787772 ]\n",
            " [306.049    ]\n",
            " [  5.959195 ]\n",
            " [ 15.098248 ]\n",
            " [ 78.97982  ]\n",
            " [  1.9038926]\n",
            " [274.77658  ]\n",
            " [ 23.906813 ]\n",
            " [196.25865  ]\n",
            " [ 13.878937 ]\n",
            " [  1.9312587]\n",
            " [  1.6854665]\n",
            " [ 12.274987 ]\n",
            " [ 14.60346  ]\n",
            " [  9.925648 ]\n",
            " [ 33.805096 ]\n",
            " [  1.7723178]\n",
            " [ 19.704016 ]\n",
            " [  1.6309587]\n",
            " [278.43338  ]\n",
            " [  1.6459779]\n",
            " [298.18463  ]\n",
            " [ 14.04287  ]\n",
            " [ 17.635733 ]\n",
            " [  1.8401226]\n",
            " [237.25676  ]\n",
            " [  1.8054029]\n",
            " [  1.6723932]\n",
            " [  1.7599145]\n",
            " [ 13.326805 ]\n",
            " [ 11.32354  ]\n",
            " [ 15.512965 ]\n",
            " [  2.1338704]\n",
            " [  1.6893646]\n",
            " [188.75404  ]\n",
            " [  2.2379546]\n",
            " [242.42038  ]\n",
            " [230.57428  ]\n",
            " [115.80776  ]\n",
            " [  1.7674837]\n",
            " [166.54073  ]\n",
            " [139.07199  ]\n",
            " [ 22.63448  ]\n",
            " [ 65.82534  ]\n",
            " [ 96.750015 ]\n",
            " [ 13.204181 ]\n",
            " [ 14.048385 ]\n",
            " [  2.137284 ]\n",
            " [224.73242  ]\n",
            " [  1.8159999]\n",
            " [  8.359248 ]\n",
            " [  1.8333534]\n",
            " [ 17.535688 ]\n",
            " [ 15.338439 ]\n",
            " [ 10.34867  ]\n",
            " [294.05893  ]\n",
            " [ 29.752035 ]\n",
            " [  1.7592541]\n",
            " [  1.7875292]\n",
            " [ 18.099918 ]\n",
            " [ 15.565677 ]\n",
            " [  5.2156706]\n",
            " [ 14.850324 ]\n",
            " [285.7313   ]\n",
            " [ 12.466629 ]\n",
            " [234.42332  ]\n",
            " [210.332    ]\n",
            " [  2.0222323]\n",
            " [137.6595   ]\n",
            " [ 16.403168 ]\n",
            " [ 22.23852  ]\n",
            " [  1.7170656]\n",
            " [  1.8978624]\n",
            " [  1.826919 ]\n",
            " [ 20.022726 ]\n",
            " [ 21.490608 ]\n",
            " [ 18.40434  ]\n",
            " [  1.8141878]\n",
            " [ 16.195639 ]\n",
            " [ 20.075583 ]\n",
            " [ 44.361572 ]\n",
            " [  1.9486345]\n",
            " [ 15.72757  ]\n",
            " [ 13.23954  ]\n",
            " [196.70937  ]\n",
            " [ 54.79128  ]\n",
            " [ 16.501043 ]\n",
            " [ 15.523562 ]\n",
            " [136.85684  ]\n",
            " [  1.7238604]\n",
            " [219.40617  ]\n",
            " [230.73013  ]\n",
            " [  9.067846 ]\n",
            " [ 13.416277 ]\n",
            " [  7.424573 ]\n",
            " [322.31662  ]\n",
            " [ 21.336653 ]\n",
            " [116.045006 ]\n",
            " [ 19.98242  ]\n",
            " [ 21.718704 ]\n",
            " [  1.6539397]\n",
            " [  1.7664243]\n",
            " [ 19.280663 ]\n",
            " [ 23.624542 ]\n",
            " [ 57.4013   ]\n",
            " [ 15.386575 ]\n",
            " [ 53.394253 ]\n",
            " [  1.8199419]\n",
            " [ 13.760866 ]\n",
            " [ 15.888683 ]\n",
            " [ 21.323368 ]\n",
            " [  1.7708555]\n",
            " [162.4171   ]\n",
            " [209.97244  ]\n",
            " [  2.1121821]\n",
            " [ 11.840753 ]\n",
            " [  1.743936 ]\n",
            " [ 14.635136 ]\n",
            " [ 29.849567 ]\n",
            " [  1.8802181]\n",
            " [  2.1377199]\n",
            " [  1.7893558]\n",
            " [ 14.28155  ]\n",
            " [  1.8328643]\n",
            " [ 22.48258  ]\n",
            " [361.59677  ]\n",
            " [  7.7221894]\n",
            " [ 15.453816 ]\n",
            " [131.87831  ]\n",
            " [  1.876191 ]\n",
            " [ 31.426252 ]\n",
            " [ 14.191078 ]\n",
            " [ 52.534428 ]\n",
            " [ 15.938353 ]\n",
            " [275.0996   ]\n",
            " [145.83171  ]\n",
            " [ 17.461302 ]\n",
            " [  2.0940852]\n",
            " [ 11.18652  ]\n",
            " [ 21.871367 ]\n",
            " [ 97.63697  ]\n",
            " [  1.8356858]\n",
            " [138.65135  ]\n",
            " [ 13.774696 ]\n",
            " [287.1578   ]\n",
            " [ 12.461515 ]\n",
            " [  1.7002071]\n",
            " [ 16.244852 ]\n",
            " [ 13.758517 ]\n",
            " [  1.6764446]\n",
            " [  2.1483278]\n",
            " [ 10.432494 ]\n",
            " [ 12.676463 ]\n",
            " [  1.7702271]\n",
            " [ 13.853646 ]\n",
            " [218.06073  ]\n",
            " [ 16.056993 ]\n",
            " [  9.197406 ]\n",
            " [239.65334  ]\n",
            " [ 26.103876 ]\n",
            " [282.68387  ]\n",
            " [197.54501  ]\n",
            " [ 32.767445 ]\n",
            " [ 19.49796  ]\n",
            " [  1.9622806]\n",
            " [ 21.310957 ]\n",
            " [ 13.507347 ]\n",
            " [117.643616 ]\n",
            " [ 19.557549 ]\n",
            " [ 17.259344 ]\n",
            " [ 15.900116 ]\n",
            " [312.56927  ]\n",
            " [137.47632  ]\n",
            " [  6.398905 ]\n",
            " [  2.1433368]\n",
            " [ 17.789364 ]\n",
            " [ 13.607406 ]\n",
            " [ 14.059146 ]\n",
            " [ 22.875633 ]\n",
            " [ 19.383854 ]\n",
            " [258.48016  ]\n",
            " [ 17.50435  ]\n",
            " [ 19.494282 ]\n",
            " [135.04915  ]\n",
            " [ 13.061321 ]\n",
            " [ 19.460262 ]\n",
            " [ 15.529609 ]\n",
            " [ 20.967735 ]\n",
            " [ 15.930852 ]\n",
            " [252.63486  ]\n",
            " [ 22.656454 ]\n",
            " [  1.891995 ]\n",
            " [ 14.492887 ]\n",
            " [ 15.996469 ]\n",
            " [ 16.289473 ]\n",
            " [ 15.540663 ]\n",
            " [ 16.025312 ]\n",
            " [ 15.749588 ]\n",
            " [ 17.52114  ]\n",
            " [ 16.610266 ]\n",
            " [  1.7187184]\n",
            " [  1.6746236]\n",
            " [267.00623  ]\n",
            " [  1.7948292]\n",
            " [340.55927  ]\n",
            " [ 15.902712 ]\n",
            " [177.17877  ]\n",
            " [ 14.085505 ]\n",
            " [  6.4741535]\n",
            " [223.90399  ]\n",
            " [ 66.80349  ]\n",
            " [ 12.826823 ]\n",
            " [ 12.505053 ]\n",
            " [ 15.995875 ]\n",
            " [240.5855   ]\n",
            " [  1.7802764]\n",
            " [  2.0426924]\n",
            " [  1.7658249]\n",
            " [192.0189   ]\n",
            " [250.73047  ]\n",
            " [323.46356  ]\n",
            " [  9.707314 ]\n",
            " [229.78296  ]\n",
            " [  1.8812344]\n",
            " [ 12.76917  ]\n",
            " [249.55359  ]\n",
            " [  1.7458166]\n",
            " [206.33559  ]\n",
            " [354.45358  ]\n",
            " [ 16.352928 ]\n",
            " [ 21.534472 ]\n",
            " [  9.186317 ]\n",
            " [ 15.353501 ]\n",
            " [ 12.410369 ]\n",
            " [  2.3071377]\n",
            " [ 13.588099 ]\n",
            " [ 14.858711 ]\n",
            " [  1.8533404]\n",
            " [  9.983235 ]\n",
            " [237.74118  ]\n",
            " [  1.8447992]\n",
            " [306.24036  ]\n",
            " [226.33878  ]\n",
            " [ 19.734299 ]\n",
            " [ 22.107664 ]\n",
            " [ 19.995687 ]\n",
            " [  1.744343 ]\n",
            " [259.25076  ]\n",
            " [ 37.849884 ]\n",
            " [240.67827  ]\n",
            " [ 95.247856 ]\n",
            " [ 15.727762 ]\n",
            " [ 12.718375 ]\n",
            " [171.5884   ]\n",
            " [235.95428  ]\n",
            " [ 16.294321 ]\n",
            " [  9.532907 ]\n",
            " [301.39383  ]\n",
            " [ 52.21435  ]\n",
            " [  1.7989929]\n",
            " [  1.8029805]\n",
            " [ 20.571692 ]\n",
            " [ 12.936579 ]\n",
            " [116.15354  ]\n",
            " [235.48679  ]\n",
            " [  1.761279 ]\n",
            " [324.42532  ]\n",
            " [ 15.529285 ]\n",
            " [ 20.093414 ]\n",
            " [ 14.960341 ]\n",
            " [ 15.027032 ]\n",
            " [ 13.369486 ]\n",
            " [220.1779   ]\n",
            " [ 21.447502 ]\n",
            " [  1.6352001]\n",
            " [ 66.14563  ]\n",
            " [313.4554   ]\n",
            " [256.07022  ]\n",
            " [194.63567  ]\n",
            " [ 18.112898 ]\n",
            " [ 66.578476 ]\n",
            " [158.75076  ]\n",
            " [ 19.40099  ]\n",
            " [  1.9765888]\n",
            " [ 13.7220745]\n",
            " [  6.836128 ]\n",
            " [  1.813975 ]\n",
            " [ 18.135544 ]\n",
            " [ 19.21622  ]\n",
            " [ 15.347786 ]\n",
            " [ 21.439713 ]\n",
            " [ 15.049628 ]\n",
            " [ 19.248276 ]\n",
            " [136.5315   ]\n",
            " [ 14.103615 ]\n",
            " [268.06406  ]\n",
            " [ 15.520865 ]\n",
            " [289.77762  ]\n",
            " [ 21.091993 ]\n",
            " [ 15.589018 ]\n",
            " [140.56992  ]\n",
            " [ 21.665257 ]\n",
            " [ 15.172987 ]\n",
            " [ 22.502201 ]\n",
            " [ 13.543472 ]\n",
            " [  2.0312784]\n",
            " [ 16.383606 ]\n",
            " [  1.80755  ]\n",
            " [ 13.746054 ]\n",
            " [ 17.171743 ]\n",
            " [  1.8169014]\n",
            " [266.54465  ]\n",
            " [ 10.740698 ]\n",
            " [ 26.741745 ]\n",
            " [  1.697476 ]\n",
            " [  1.6783338]\n",
            " [183.72858  ]\n",
            " [  1.7322823]\n",
            " [ 12.916524 ]\n",
            " [ 22.913712 ]\n",
            " [213.43185  ]\n",
            " [  8.428808 ]\n",
            " [  9.410304 ]\n",
            " [225.46358  ]\n",
            " [219.04099  ]\n",
            " [ 14.636299 ]\n",
            " [ 15.028224 ]\n",
            " [ 16.5564   ]\n",
            " [ 12.536661 ]\n",
            " [220.83029  ]\n",
            " [347.1707   ]\n",
            " [216.81598  ]\n",
            " [ 19.546495 ]\n",
            " [185.93987  ]\n",
            " [  7.4925637]\n",
            " [268.07156  ]\n",
            " [121.735146 ]\n",
            " [  1.8181717]\n",
            " [235.91565  ]\n",
            " [292.02457  ]\n",
            " [  1.8140162]\n",
            " [ 10.470348 ]\n",
            " [212.6993   ]\n",
            " [ 21.463907 ]\n",
            " [  2.0031414]\n",
            " [ 12.218878 ]\n",
            " [ 54.41236  ]\n",
            " [  1.7802986]\n",
            " [ 14.847513 ]\n",
            " [ 15.098148 ]\n",
            " [  1.7882459]\n",
            " [  1.8334384]\n",
            " [  1.7159638]\n",
            " [ 16.120909 ]\n",
            " [ 18.460966 ]\n",
            " [ 22.170168 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J84W_1eEhFlK",
        "outputId": "ccf25de7-96c4-4b53-e3f0-f895233378af"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13660.87890625, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test loss: {}'.format(score[0]))\n",
        "print('Test accuracy: {}'.format(score[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1wHkkzhIHm",
        "outputId": "60e144ef-2b52-4feb-f38b-dbb6fac92c4d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 13660.87890625\n",
            "Test accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Features"
      ],
      "metadata": {
        "id": "k52DJfjFYYa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.activations import relu, sigmoid, tanh\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "activations = [relu, sigmoid, tanh]\n",
        "layers = [[64], [64, 32], [128, 64, 32]]\n",
        "optimizers = [SGD(), Adam()]\n",
        "kernels = [[32, (3,3)], [64, (3,3)], [64, (5,5)], [128, (5,5)]]\n",
        "lstm_layers = [[32], [64], [32, 32], [64, 32]]\n",
        "\n",
        "# Define a function to create the model with a given set of hyperparameters\n",
        "def create_model(activation, layer_sizes, optimizer, kernel=None, lstm_layer_sizes=None):\n",
        "    model = Sequential()\n",
        "    if kernel:\n",
        "        model.add(Conv2D(kernel[0], kernel_size=kernel[1], activation=activation, input_shape=input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "    elif lstm_layer_sizes:\n",
        "        if len(lstm_layer_sizes) == 1:\n",
        "            model.add(LSTM(lstm_layer_sizes[0], input_shape=input_shape))\n",
        "        else:\n",
        "            model.add(LSTM(lstm_layer_sizes[0], input_shape=input_shape, return_sequences=True))\n",
        "            for size in lstm_layer_sizes[1:-1]:\n",
        "                model.add(LSTM(size, return_sequences=True))\n",
        "            model.add(LSTM(lstm_layer_sizes[-1]))\n",
        "    else:\n",
        "        model.add(Flatten(input_shape=input_shape))\n",
        "    for size in layer_sizes:\n",
        "        model.add(Dense(size, activation=activation))\n",
        "        model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Define a function to run the hyperparameter search\n",
        "def run_experiment():\n",
        "    best_rmse = float('inf')\n",
        "    best_params = None\n",
        "    for activation in activations:\n",
        "        for layer_sizes in layers:\n",
        "            for optimizer in optimizers:\n",
        "                for kernel in kernels:\n",
        "                    for lstm_layer_sizes in lstm_layers:\n",
        "                        model = create_model(activation, layer_sizes, optimizer, kernel, lstm_layer_sizes)\n",
        "                        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "                        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
        "                        y_pred = model.predict(X_test)\n",
        "                        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "                        if rmse < best_rmse:\n",
        "                            best_rmse = rmse\n",
        "                            best_params = {'activation': activation.__name__, 'layer_sizes': layer_sizes, 'optimizer': optimizer.__class__.__name__, 'kernel': kernel, 'lstm_layer_sizes': lstm_layer_sizes}\n",
        "    return best_params, best_rmse\n",
        "\n",
        "# Run the hyperparameter search\n",
        "best_params, best_rmse = run_experiment()\n",
        "\n",
        "# Print the best hyperparameters and RMSE score\n",
        "print('Best hyperparameters:', best_params)\n",
        "print('\n"
      ],
      "metadata": {
        "id": "hxFMkNegWZUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}